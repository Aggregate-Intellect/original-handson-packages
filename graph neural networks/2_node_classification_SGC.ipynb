{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2_node_classification_SGC_check_final.ipynb","provenance":[{"file_id":"1x2ldf37j3fwO6CRRTeQs50p-p8qvPHVA","timestamp":1622937696554}],"collapsed_sections":["_-zNP2RMJW8X","cegWvG7VYD-d"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"14HW9foK-jSk"},"source":["# Node Classification\n","\n","In this notebook, we will be looking at node classification problems. In this setting, a graph is provided with some labeled nodes and some unlabeled nodes, and the task is to train a model that predicts the labels of the unlabeled nodes. Examples of this include predicting the research categories of publications in a citation network, or predicting interests of a user in a social network.\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"yJXckpuqsr6y"},"source":["## Transductive Node Classification"]},{"cell_type":"markdown","metadata":{"id":"WVdiVYEGsupe"},"source":["In a transductive node classification setting:\n","\n","\n","*   The features of all nodes in one graph are known\n","*   Some of the node labels are known\n","*   Goal: Predict unknown node labels in the same graph\n","\n","<center>\n","<img src=\"https://ai.science/api/authorized-images/ZHAan1V7Hz7YV0%2BRVLeqR9qa1Eaam83R2A8TDhqP7ugb2T6SQZBujucyoNn8Cxr%2FJCIo%2BvdirgOq%2FFP%2Fp47GdfZaYXQe5bXZTfw0vsIsjGB2ZpJOfKYlNOq8bePoVFr4X4DN0bgMEoXB19hlk7KMFEljiu8PatOb3MKQjKYWBtrFcJCqFjOaWrGQ260G%2F9PnUTqF74r0BXT4mc6C50UizvrBhyJkoQbNdA6CnG62rB6TN0JTQjhE3%2Fo%2BLu2Te6Gpc5zUmPG5KEuN0aSNtlwml82uZAtV0srMU6YdsMlh5eJYRXPgQD0PHO3PpFcsKIsyAi%2BPkDLO4gx%2FMFedDaNdSkfRL01dycLpNHvg7YrtWi0TCMxwQF2D4i4ua3beHP0E7sfogTti%2BwaBkeE8xKZBNTxJd78ZQFIEmzEEbR%2FI%2FS8OxUDMTnI5lGL872nfT47KaZcW4BgQMpEmqluNdWtQEQifwUedi4XjEWBqewIN9rcaVOLyRbIDAtphrxS%2Be8AQt4tnkbnCxDQxsiOfb%2BIyVm4JzeMSjxO5jVBRgiAcKOx4UCoNbMtmVEjglJQS%2BrKODOIZOXJ%2BsVjJwOtnTvr%2FzDsbqZojvECAW98ITDKbuewrKBCr7cKy82mE8C8NARgwr5uSRzR8Euy3xEu7gJM%2BfhdXB5oRlzGGoBpCo3bm2Oo%3D\" width=\"60%\" > </center>"]},{"cell_type":"markdown","metadata":{"id":"kfumhme3tYNU"},"source":["## Inductive Node Classification"]},{"cell_type":"markdown","metadata":{"id":"MeGfy2pstbJ4"},"source":["In an inductive node classification setting:\n","\n","*   The features of nodes in one or more graphs are known\n","*   Some or all of the node labels in those graphs are known\n","*   Goal: Predict unkown node labels in unseen graphs\n","\n","\n","<center>\n","<img src=\"https://ai.science/api/authorized-images/cUEc1VHs2beXboMFOl3uQ8MyReaWjSTJbt7Xdc4evnlGiyIjfFbtgKX79az37YEGEOnSA%2BZiYsH%2Bexjqp4TheDH1cVsMZ4Y8pHwk%2FFt1KBox2AJ4syhJLq0DaY627JAMfo2T06rowYtPGNJjlvp%2BpznhQ39QCfuxNZGjCf2pO0j2zugxHm4YviF9Knods2J6MRiQIFg7wYEg5jWfstY0Q5AfQEu9BBNRke3ngG769tpixVkXRhU7hr37m38tFZhMqzZriRE7tyJ64HR%2F5ewJihu%2FRuh5Wz6uYEE%2FdK8bBX6%2FyLrk79oxA1roOURtVQO%2Bng04fIXu3GD%2FFfPDA%2BrQlryLRUSsvgaeeGJI95alp51MWoSRbivoFEqA4aCEZhuKYIA9GI1jqXScwgr3UvtEH6fDSNbghcwFggMFZNZ8l%2F2tixwWAVC6ibdfw3TcDAZIcByv%2BBZ2HCy%2BbEMaXboMLB7h5rlvimJhOXUYYwitz8S8IO3PpHvIHMYT6Yo6X319L1SYzHtcCJa5ZKkO4fjuGBtcsOJUCZQRp4c0kyTkhcMmdkFnnrUet5eEzBr6PoeSf4WgRaZNiEvbPf0fJ%2FRcfhAphn4TqIohrZcMlRDbC9hl4z3EK8h0DxYTCL1sBqIM8tNO1MDPGh4UtipdFIT9OjjuFJFvMvdcQcymOHJ03eM%3D\" width=\"60%\" > </center>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_-zNP2RMJW8X"},"source":["# Installation\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ESThntq91KrW","executionInfo":{"status":"ok","timestamp":1623852590133,"user_tz":240,"elapsed":102565,"user":{"displayName":"Ryan Cohn","photoUrl":"","userId":"01706064865196246875"}},"outputId":"6f9e681f-00c7-4974-c3c9-1df6af61a7c4"},"source":["!pip uninstall -y torch torchvision torchtext fastai\n","!pip install torch==1.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n","\n","!pip install torch-scatter==latest+cu101 torch-sparse==latest+cu101 -f https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.6.0.html\n","!pip install torch-spline-con==latest+cu101 torch-scatter==latest+cu101 -f https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.6.0.html\n","!pip install torch-sparse==latest+cu101 -f https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.6.0.html\n","\n","!pip install torch-geometric==1.6.1"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Uninstalling torch-1.6.0+cu101:\n","  Successfully uninstalled torch-1.6.0+cu101\n","\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\n","\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\n","\u001b[33mWARNING: Skipping fastai as it is not installed.\u001b[0m\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.6.0+cu101\n","  Using cached https://download.pytorch.org/whl/cu101/torch-1.6.0%2Bcu101-cp37-cp37m-linux_x86_64.whl\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0+cu101) (0.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0+cu101) (1.19.5)\n","Installing collected packages: torch\n","Successfully installed torch-1.6.0+cu101\n","Looking in links: https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.6.0.html\n","Collecting torch-scatter==latest+cu101\n","  Using cached https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.6.0/torch_scatter-latest%2Bcu101-cp37-cp37m-linux_x86_64.whl\n","Collecting torch-sparse==latest+cu101\n","  Using cached https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.6.0/torch_sparse-latest%2Bcu101-cp37-cp37m-linux_x86_64.whl\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse==latest+cu101) (1.4.1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse==latest+cu101) (1.19.5)\n","Installing collected packages: torch-scatter, torch-sparse\n","  Found existing installation: torch-scatter 2.0.5\n","    Uninstalling torch-scatter-2.0.5:\n","      Successfully uninstalled torch-scatter-2.0.5\n","  Found existing installation: torch-sparse 0.6.8\n","    Uninstalling torch-sparse-0.6.8:\n","      Successfully uninstalled torch-sparse-0.6.8\n","Successfully installed torch-scatter-2.0.5 torch-sparse-0.6.8\n","Looking in links: https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.6.0.html\n","\u001b[31mERROR: Could not find a version that satisfies the requirement torch-spline-con==latest+cu101 (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for torch-spline-con==latest+cu101\u001b[0m\n","Looking in links: https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.6.0.html\n","Collecting torch-sparse==latest+cu101\n","  Using cached https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.6.0/torch_sparse-latest%2Bcu101-cp37-cp37m-linux_x86_64.whl\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse==latest+cu101) (1.4.1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse==latest+cu101) (1.19.5)\n","Installing collected packages: torch-sparse\n","  Found existing installation: torch-sparse 0.6.8\n","    Uninstalling torch-sparse-0.6.8:\n","      Successfully uninstalled torch-sparse-0.6.8\n","Successfully installed torch-sparse-0.6.8\n","Requirement already satisfied: torch-geometric==1.6.1 in /usr/local/lib/python3.7/dist-packages (1.6.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.6.1) (1.4.1)\n","Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.6.1) (0.4)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.6.1) (2.5.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.6.1) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.6.1) (1.19.5)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.6.1) (0.22.2.post1)\n","Requirement already satisfied: rdflib in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.6.1) (5.0.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.6.1) (1.1.5)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.6.1) (1.6.0+cu101)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.6.1) (3.1.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.6.1) (2.11.3)\n","Requirement already satisfied: ase in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.6.1) (3.21.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.6.1) (4.41.1)\n","Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.6.1) (0.51.2)\n","Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->torch-geometric==1.6.1) (4.4.2)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==1.6.1) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==1.6.1) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==1.6.1) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==1.6.1) (2021.5.30)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric==1.6.1) (1.0.1)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric==1.6.1) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric==1.6.1) (1.15.0)\n","Requirement already satisfied: isodate in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric==1.6.1) (0.6.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric==1.6.1) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric==1.6.1) (2018.9)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch->torch-geometric==1.6.1) (0.16.0)\n","Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->torch-geometric==1.6.1) (1.5.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric==1.6.1) (2.0.1)\n","Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ase->torch-geometric==1.6.1) (3.2.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->torch-geometric==1.6.1) (57.0.0)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->torch-geometric==1.6.1) (0.34.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric==1.6.1) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric==1.6.1) (1.3.1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9htnPB9fZ7xA"},"source":["# Loading Datasets\n","For our datasets, we will be using three citation networks; Pubmed, Cora and Citeseer. Nodes correspond to publications and edges correspond to citations. The citation networks are available through the Planetoid dataset of PyG."]},{"cell_type":"code","metadata":{"id":"oArjAIk5Jdhd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623852599440,"user_tz":240,"elapsed":9339,"user":{"displayName":"Ryan Cohn","photoUrl":"","userId":"01706064865196246875"}},"outputId":"922b90ea-3474-429b-f425-4f8289ee5544"},"source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.datasets import Planetoid\n","import torch_geometric.transforms as T\n","\n","#Load the Cora, CiteSeer and Pubmed citation networks\n","#Note: T.NormalizeFeatures() creates a transform that normalizes the node features\n","dataset_cora = Planetoid(root=\"./tmp\", name=\"Cora\", transform=T.NormalizeFeatures())\n","dataset_citeseer = Planetoid(root=\"./tmp\", name=\"CiteSeer\", transform=T.NormalizeFeatures())\n","dataset_pubmed = Planetoid(root=\"./tmp\", name=\"Pubmed\",transform=T.NormalizeFeatures())\n","\n","data_cora = dataset_cora[0]\n","data_citeseer = dataset_citeseer[0]\n","data_pubmed = dataset_pubmed[0]\n","\n","print(\"Citation network information\")\n","print(\"Cora: \", data_cora)\n","print(\"Citeseer: \", data_citeseer)\n","print(\"Pubmed: \", data_pubmed)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Citation network information\n","Cora:  Data(edge_index=[2, 10556], test_mask=[2708], train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708])\n","Citeseer:  Data(edge_index=[2, 9104], test_mask=[3327], train_mask=[3327], val_mask=[3327], x=[3327, 3703], y=[3327])\n","Pubmed:  Data(edge_index=[2, 88648], test_mask=[19717], train_mask=[19717], val_mask=[19717], x=[19717, 500], y=[19717])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fTIYE2vyfnB3"},"source":["# Generalizing Convolutional Operators to Graphs"]},{"cell_type":"markdown","metadata":{"id":"X8MB8fKYyJfL"},"source":["## Convolutional Operator on a 2-d grid"]},{"cell_type":"markdown","metadata":{"id":"oWMpKmPLfupz"},"source":["Let's consider an image represented by numbers on a 2-d grid and review what happens in a convolutional layer typically used in convolutional neural networks (CNNs). A learnable filter (typically of size $3 \\times 3$)  convolves across the grid and an element-wise multiplication of the filter values by the image values is computed at all positions.  The output of this operation is also numbers on a 2-d grid, which could be of the same size or not depending on whether padding was used. (For more details on CNNs see this [page](https://cs231n.github.io/convolutional-networks/). )\n","\n","\n","<center>\n","<img src=\"https://ai.science/api/authorized-images/ZbbQlWsB8df1DpFwUiY9AS7TapF%2BH9nv%2FX8vCzV9inQ7KYk4uS2WDm%2FAGXepIuwVXbrnn%2Bxyd8wcGv1KU0EYmqB6noUpulGGRJ2ycVSITeuh8gyGXq4huY7vyETRq3lGYaClBN6etDJuu5rFAe89nBALS8JNeAXKE2VTac8iHpwMnk%2FRtWnoReqL67ZK1TFg9fsWjwgs8t7XMD%2F5rzxFCJh4rqXoI6F4PuANumyYiAU8OiLW8LTjxHREsF4MV28zJCWHxVQLa%2BJzyIoHTQrkkCL0yExVz4sX%2Fxx9ZnbS7Vr14TLb2PqkyKPg%2BwHQ9wNjkTP74KsX3A1eSlEKBum0xa3xb5XdF2QHQDl9vMNDNxzCO2WbVW%2B2l3Vo%2BsZbZ3qu4Lw6QtgBdbRY%2B2%2FAJyo79W72M9OsGB70ZJJnW6%2FZEcYmtKuE37%2FeNqKKKOP0XcP6zqFobi69E9fTgUIB%2Bvh0TO%2F%2Bl%2BFoxbPvP3LJfeylPi1Xh2OJgB03o%2F2lm8Psw9SiCywKIF8z2IDYJ6zfPa0UUUp3WyiJGNSba8znBgH%2BgiCe4uyQKtQ6x8vxvDlMHZMzXqyj%2Bhed2CanR0JsrJhNeSUP09kkMorCvFyWIWK8%2B%2FwPqgB0CA4RonWgmFJiQfyNdH0YMILNs0QHFk2pEA34zo08r1jg15lYhqDCF7F3fL0%3D\" width=\"60%\" > </center>\n","\n","The convolutional filter in CNNs has some desirable properties that are suitable for images:\n","\n","*   The number of parameters is independent of the input \n","*   Operates locally, extracting localized features\n","*   Translation invariant (i.e. the filter remains the same as it convolves)\n","*   Values of the filters  depend on the relative position of neighboring pixels. (e.g. the 9 values in a $3 \\times 3$ filter can in general be different)\n","\n","So what are the challenges in generalizing a convolutional operator to arbitrary graphs? Some of the difficulties that make such a generalization non-trivial is:\n","\n","*   A node in a graph may have an arbitrary number of neighbors, while a pixel in an image has 8 neighbors (except in the case of edge and corner pixels)\n","*   A node in a graph may have an arbitrary number of and types of attributes. E.g. Whereas a pixel in a color image may have three values (RGB), a node in a social network representing a user may different types of attributes such as current location, interests, etc.\n","*  In the case of a heterogeneous graph, there may be different types of nodes. E.g. in a movie-actor network.\n"," \n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2fgvEKYwuo8L"},"source":["# Extension to Homogeneous Graphs with Node Features\n"]},{"cell_type":"markdown","metadata":{"id":"s1nPidyQFDvR"},"source":["Let's try to create a convolution-like operator on a homogeneous graph. Let's assume that each node $v_i$  has a feature vector $\\mathbf{v}_i$ associated with it. \n","\n","<center><img src=\"https://ai.science/api/authorized-images/ly8YBPB1rsFZENZBrO47vYhzp5zBRXRO8%2FtHMMBtBm%2FkhYTNnnl7B2rHuVk0MoMOxY8WDh2R9uMBuqwkMjT1fGntAM2p2agcwmciMtSrIPBZiVWvRH%2FcSC%2FPRgyyLy0LRiBeqbNPvIetT6J7cKKRB6t3OUL9vXnlI9bMPSBrNIDH9pblYjIs48BtthsR4FLtXPp5H25nq4dyn0K6cvONLIebrOEoAmbtL8x3DxJHnmBfEoKdHU%2B6yxSCQJk14%2BUkUSiutxov2UCJnzCzPXQuyyFTieRFXe4zkzqcjhLljBLHwGDorWlDZTSAF2dqN6%2BVvl5Bu1JKk1iY7wLluejjS7lfxGaeeiLS0SE34ChjXe9XVvXJAnZ%2Fr7uOlgKhytDfdquuGtFJlHs4b0ODZ2AVuFFCS6h%2FVLAPt1FHHBcEgcAv5Gnk7Gs3hAPZ57beBqaLe7sWdzJA7RRWaedUnO%2FyxGQg8MvYSjDXyz0H3yZi8acLUtCkme8W73WO1io%2FaXTeWteXRHDvUI42kMrqjcyqfoy7gdGzyO6CsYk6BvzGeR7ralzvzjPVVSn8wvvsa3dDECAfXex%2BFyCsAv6HqurD%2FwNeqK%2FB9B1r4ydqTc6On2ZLx4db8JJq6zW8NVHUwfwTJRrVuJY5V2m8QlWr3LLu3Xz10Urt255yAgkXFvLfRaw%3D\" width=\"30%\" > </center>\n","\n","\n","A very simple convolution like operator on graphs is just the uniform average of the node-features of each node’s neighborhood. \n","\n","Let's go through a single layer of this operation. We start with the initial feature vectors at each node as the input to the convolution layer:\n","$$\\mathbf{v}_i^{(0)}= \\mathbf{v}_i$$\n","\n","Then we update each node’s features by the average of all neighboring node features. This can be written as:\n","\n","\n","$$ \\mathbf{v}_i^{(1)} = \n","\\sum_{v_j \\in N(v_i) \\cup v_i }{\\frac{1}{d_i + 1}  \\mathbf{v}_i^{(0)}} $$\n","\n","This is visualized below\n","\n","<center><img src=\"https://ai.science/api/authorized-images/twlUnmkDyXflUxLUbaJlYVxoyPsrO9lCxMIwGcllts3fshttjk2otcAN%2F%2BYT%2BzCn%2B7zCcSTq73x08Sjx%2BuQw1XaZqeC6PEQJDT01QzpVHtvVN%2FtKMOfCiUmHYA2Sn%2FEOxTKY%2BDeIliDYlQM2efGAHfvumXEOynZJdAPbJdhrHo2y0j0oYdInscZkr5PHzHVrWqtxIaJCMriCJ5UlVxfIHvH8%2Frf3VOBW5H2Cwu%2F6vjww0wOhvrq60ygHE99Sghzo0pmkuk8Fq6OYw2t5MgL2azS0KZEnSOf%2F5zeKGYBwUE3czdz5BlPZAVZvV7UYGb4jlmohvMNWmwKY8e%2F4wvtG5iUtzUZpMvSTCsvdl0NIxbJ1He7gykW%2BfaAQRjiO1Nme%2B%2FD9o2BaVzGX61eu4vlPJZYGZh3JUgBGGtWMEFmOETMPMt5CYoHas0z5Dk2xIk5DkYS1F%2B4FIlc8ywacJoih7miZcUIPjeWFiVvGMtrv0zuofNZrV7gb%2Bw2mm3YPVSg6uCPslo2phKBFpkrLb7iy6OBGMGqElRa1ofK81zJ4EUMs%2FnAt0TkE6DOZtsQlEsXI4%2B4fuMoFs2fdlcgb%2B4rBU2efOjfO5nQptHlvbTXTccmI6IIU0AY%2BiSimB7QysH%2FqT%2F%2FY1iOI9WObaDfecUpK8OYLnyaOeZCp0NNP5ILbINk%3D\" width=\"30%\" > </center>\n","\n","In the illustration here, the neighborhood of each node consists of all nodes with incoming edges to that node. This definition of a neighborhood is to take into account the propagation of information. However other definitions of neighborhoods are possible, and the neighborhood doesn’t have to be limited to nodes that are only 1 hop away.\n","\n","If we write $D$ as the degree matrix, i.e. a diagonal matrix containing the number of neighbors of each node on its diagonals, $I$ as the identity matrix and $A$ as the adjacency matrix, then we can succinctly write this simple convolution operator as \n","\n","$$ V^{(1)} =(D+I)^{−1} (A+I) V^{0}, $$\n","\n","where $V$ is a $N^v \\times N^{f_{nodes}}$ matrix containing the feature-vectors stacked vertically. Introducing $\\tilde{S}=(D+I)^{−1} (A+I)$, this can be written as \n","\n","$$ V^{(1)} =\\tilde{S}V^{0}$$\n","We can apply this step $k$ times to get  \n","\n","$$ V^{(k)} =\\tilde{S}V^{0}.$$\n","After $k$ applications, the updated node features of a all nodes will have been influenced by the input feature-vectors of nodes that are up to $k$ hops away. There is however a limitation to how many times we can repeat this operation. For example if the graph has a diameter of 5, that is the largest shortest-path between any pair of nodes is 5, and we repeat this averaging operation 5 times,  the node features in the final layer would be very similar. This would probably result in poor performance in downstream tasks like node classification.\n","\n","\n","After computing  $V^{(k)}$, we can then use these updated feature-vectors for downstream tasks. For example for node classification, one can pass $V^{(k)}$ into a softmax layer to predict the label of each node, i.e. \n","\n","$$ \\hat{Y}= softmax(V^{(k)}\\Theta ),$$\n","where $\\Theta$ is a matrix to be learned e.g. via back-propagation.\n","\n","While the above procedure is simple, it is still a good baseline for graph representations of data and is benchmarked in the paper [Simplifying Graph Convolutional Networks](https://arxiv.org/abs/1902.07153). "]},{"cell_type":"markdown","metadata":{"id":"PhZ0FJrxccNR"},"source":["# Simple Graph Convolutonal Network\n","\n","We will first implement a simple learning pipleline based on the graph convolutional operator from the paper [Simplifying Graph Convolutional Networks](https://arxiv.org/abs/1902.07153). \n","\n","The [*SGConv*](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.SGConv) operator is linear. For each node, the operator essentially averages the features from neighboring nodes. Applying this averaging $K$ times allows features to propagate from nodes that are at most $K$ edges apart.\n","\n","*Note: We will look at the details of how the convolutonal operators are implemented in the next notebook. For now we will simply use the ones provided in PyG.*\n","\n","Let's apply a single SGConv layer to the node features of the Cora graph. We will define the layer to have $N^{f_{nodes}}$ input channels (i.e. the length of the feature vector of each node) and output $N^C$ channels (i.e. the number unique labels)."]},{"cell_type":"code","metadata":{"id":"F3rg-Szny4BM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623852599975,"user_tz":240,"elapsed":559,"user":{"displayName":"Ryan Cohn","photoUrl":"","userId":"01706064865196246875"}},"outputId":"d9e87473-e53d-4a34-924d-5cfda047856e"},"source":["from torch_geometric.nn import SGConv\n","\n","num_classes = len(data_cora.y.unique())\n","\n","conv = SGConv(in_channels=data_cora.num_features, out_channels=num_classes,\n","       K=1, cached=True)\n","\n","x  = data_cora.x\n","print(\"Shape before applying convoluton: \", x.shape)\n","\n","#x contains the node features, and edge_index encodes the structure of the graph\n","x  = conv(x, data_cora.edge_index)\n","print(\"Shape after applying convoluton: \", x.shape)\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Shape before applying convoluton:  torch.Size([2708, 1433])\n","Shape after applying convoluton:  torch.Size([2708, 7])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NMdpv-Q63WBp"},"source":["Let's define a network which uses SGConv to classify nodes on the Cora dataset"]},{"cell_type":"code","metadata":{"id":"i2isvLPqciVd","executionInfo":{"status":"ok","timestamp":1623852599976,"user_tz":240,"elapsed":7,"user":{"displayName":"Ryan Cohn","photoUrl":"","userId":"01706064865196246875"}}},"source":["class SGNet(torch.nn.Module):\n","    def __init__(self, data, K=1):\n","        super().__init__()\n","        num_classes = len(data.y.unique())\n","\n","        # Create a Simple convolutional layer with K neighbourhood \n","        # \"averaging\" steps\n","        self.conv = SGConv(in_channels=data.num_features,\n","                            out_channels=num_classes, \n","                           K=K, cached=True)\n","\n","    def forward(self, data):\n","        # Apply convolution to node features\n","        x = self.conv(data.x, data.edge_index)\n","\n","        # Compute log softmax.\n","        # Note: Negative log likelihood loss expects a log probability\n","        return F.log_softmax(x, dim=1) \n"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wg1v_BfR5cG5"},"source":["We will define a function to run one training cycle of the model"]},{"cell_type":"code","metadata":{"id":"PXbGwaNApF73","executionInfo":{"status":"ok","timestamp":1623852599977,"user_tz":240,"elapsed":7,"user":{"displayName":"Ryan Cohn","photoUrl":"","userId":"01706064865196246875"}}},"source":["def train(model, data, optimizer):\n","  # Set the model.training attribute to True\n","  model.train() \n","\n","  # Reset the gradients of all the variables in a model\n","  optimizer.zero_grad() \n","\n","  # Get the output of the network. The output is a log probability of each\n","  log_softmax = model(data) \n","\n","  labels = data.y # Labels of each node\n","\n","  # Use only the nodes specified by the train_mask to compute the loss.\n","  nll_loss = F.nll_loss(log_softmax[data.train_mask], labels[data.train_mask])\n","  \n","  #Computes the gradients of all model parameters used to compute the nll_loss\n","  #Note: These can be listed by looking at model.parameters()\n","  nll_loss.backward()\n","\n","  # Finally, the optimizer looks at the gradients of the parameters \n","  # and updates the parameters with the goal of minimizing the loss.\n","  optimizer.step() "],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DCMhU2xurA48"},"source":["In case you are not very familiar with Pytorch: To get a better sense of what the above function does (or anything you are not quite sure down the line), you can just run the code and see what is going on yourself! Here is an example:"]},{"cell_type":"code","metadata":{"id":"qldh-1t9pH1l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623852600516,"user_tz":240,"elapsed":545,"user":{"displayName":"Ryan Cohn","photoUrl":"","userId":"01706064865196246875"}},"outputId":"24e5e282-7bcf-4472-fceb-4debfb2ec9cd"},"source":["model_cora = SGNet(data_cora, K=1)\n","optimizer = torch.optim.Adam(model_cora.parameters(), lr=0.2)\n","\n","optimizer.zero_grad() \n","\n","print(\"=\"*80)\n","print(\"Gradients of model parameters right after zero_grad\")\n","for i, parameter in model_cora.named_parameters():\n","  print (\"Parameter {}\".format(i))\n","  print (\"Shape: \",parameter.shape )\n","  print(\"Gradient\")\n","  print(parameter.grad)\n","\n","# Get the output of the network. The output is a log probability of each\n","log_softmax = model_cora(data_cora) \n","\n","print(\"=\"*80)\n","print(\"Output of model (log-softmax) \\n Shape:{}\"\n","      \" \\n Values: {}\".format(log_softmax.shape, log_softmax))\n","\n","# Labels of each node\n","y_true = data_cora.y \n","\n","# Use only the nodes specified by the train_mask to compute the loss.\n","train_mask = data_cora.train_mask\n","nll_loss = F.nll_loss(log_softmax[train_mask], y_true[train_mask])\n","\n","print(\"=\"*80)\n","print(\"negative logloss {}\".format(nll_loss))\n","\n","#Computes the gradients of all model parameters used to compute the nll_loss\n","#Note: These can be listed by looking at model.parameters()\n","nll_loss.backward()\n","\n","print(\"=\"*80)\n","print(\"Gradients of model parameters right after back propagation\")\n","for i, parameter in model_cora.named_parameters():\n","  print (\"Parameter {}\".format(i))\n","  print (\"Shape: \",parameter.shape )\n","  print(\"Gradient\")\n","  print(parameter.grad)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["================================================================================\n","Gradients of model parameters right after zero_grad\n","Parameter conv.lin.weight\n","Shape:  torch.Size([7, 1433])\n","Gradient\n","None\n","Parameter conv.lin.bias\n","Shape:  torch.Size([7])\n","Gradient\n","None\n","================================================================================\n","Output of model (log-softmax) \n"," Shape:torch.Size([2708, 7]) \n"," Values: tensor([[-1.9316, -1.9705, -1.9500,  ..., -1.9456, -1.9391, -1.9405],\n","        [-1.9324, -1.9668, -1.9511,  ..., -1.9463, -1.9360, -1.9404],\n","        [-1.9319, -1.9663, -1.9489,  ..., -1.9481, -1.9372, -1.9405],\n","        ...,\n","        [-1.9356, -1.9665, -1.9528,  ..., -1.9475, -1.9377, -1.9352],\n","        [-1.9334, -1.9662, -1.9475,  ..., -1.9456, -1.9380, -1.9418],\n","        [-1.9328, -1.9676, -1.9495,  ..., -1.9453, -1.9377, -1.9423]],\n","       grad_fn=<LogSoftmaxBackward>)\n","================================================================================\n","negative logloss 1.945770263671875\n","================================================================================\n","Gradients of model parameters right after back propagation\n","Parameter conv.lin.weight\n","Shape:  torch.Size([7, 1433])\n","Gradient\n","tensor([[-4.3987e-06,  1.2867e-04, -6.8989e-05,  ..., -3.7922e-05,\n","         -3.9255e-05,  4.2869e-05],\n","        [-1.7303e-05, -2.9545e-04, -1.8208e-04,  ...,  2.1084e-05,\n","         -1.2050e-04, -4.1290e-06],\n","        [-2.4609e-05,  1.2697e-04, -3.0771e-05,  ...,  2.1505e-05,\n","          1.8045e-04,  8.9100e-05],\n","        ...,\n","        [-1.1357e-05,  1.2687e-04,  2.1596e-05,  ...,  2.1495e-05,\n","          8.3314e-05,  6.4128e-05],\n","        [ 1.9299e-05, -4.8893e-05,  8.3946e-05,  ...,  2.1695e-05,\n","         -2.6458e-04,  9.0001e-05],\n","        [ 1.9264e-05, -1.0414e-04,  9.5170e-05,  ...,  2.1663e-05,\n","          1.4816e-04,  8.9877e-05]])\n","Parameter conv.lin.bias\n","Shape:  torch.Size([7])\n","Gradient\n","tensor([ 0.0019, -0.0030, -0.0002, -0.0004, -0.0003,  0.0012,  0.0007])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZiT-OtSr_reu"},"source":["Now let's define a function to test the accuracy of a trained model on the validation set"]},{"cell_type":"code","metadata":{"id":"eHy8WPWB_Gmq","executionInfo":{"status":"ok","timestamp":1623852600518,"user_tz":240,"elapsed":11,"user":{"displayName":"Ryan Cohn","photoUrl":"","userId":"01706064865196246875"}}},"source":["def compute_accuracy(model, data, mask):\n","  # Set the model.training attribute to False\n","  model.eval()\n","  logprob = model(data)\n","  _, y_pred = logprob[mask].max(dim=1)\n","  y_true=data.y[mask]\n","  acc = y_pred.eq(y_true).sum()/ mask.sum().float()\n","  return acc.item()\n","\n","@torch.no_grad() # Decorator to deactivate autograd functionality  \n","def test(model, data):\n","  acc_train = compute_accuracy(model, data, data.train_mask)\n","  acc_val = compute_accuracy(model, data, data.val_mask)\n","\n","  return acc_train, acc_val"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"smaqQsciOZ8i"},"source":["Putting it all together in a training loop"]},{"cell_type":"code","metadata":{"id":"dTkB2KhlMVGU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623852602519,"user_tz":240,"elapsed":2009,"user":{"displayName":"Ryan Cohn","photoUrl":"","userId":"01706064865196246875"}},"outputId":"ed1b1c46-0582-4c32-c723-307cf6cdae0b"},"source":["# Create a model for the Cora dataset\n","model_cora = SGNet(data_cora, K=1)\n","\n","# Create an Adam optimizer with learning rate and weight decay (i.e. L2 regularization)\n","optimizer = torch.optim.Adam(model_cora.parameters(), lr=0.001, weight_decay=5e-4)\n","\n","for epoch in range(1, 200):\n","    train(model_cora, data_cora, optimizer)\n","    if epoch %10 ==0:\n","      log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}'\n","      print(log.format(epoch, *test(model_cora,data_cora)))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Epoch: 010, Train: 0.5143, Val: 0.1820\n","Epoch: 020, Train: 0.9857, Val: 0.6620\n","Epoch: 030, Train: 0.9929, Val: 0.7000\n","Epoch: 040, Train: 0.9929, Val: 0.7180\n","Epoch: 050, Train: 0.9929, Val: 0.7220\n","Epoch: 060, Train: 0.9929, Val: 0.7220\n","Epoch: 070, Train: 0.9929, Val: 0.7200\n","Epoch: 080, Train: 0.9929, Val: 0.7220\n","Epoch: 090, Train: 0.9929, Val: 0.7240\n","Epoch: 100, Train: 0.9929, Val: 0.7280\n","Epoch: 110, Train: 0.9929, Val: 0.7240\n","Epoch: 120, Train: 0.9929, Val: 0.7240\n","Epoch: 130, Train: 0.9929, Val: 0.7280\n","Epoch: 140, Train: 0.9929, Val: 0.7280\n","Epoch: 150, Train: 0.9929, Val: 0.7320\n","Epoch: 160, Train: 0.9929, Val: 0.7360\n","Epoch: 170, Train: 0.9929, Val: 0.7380\n","Epoch: 180, Train: 0.9929, Val: 0.7360\n","Epoch: 190, Train: 0.9929, Val: 0.7380\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cegWvG7VYD-d"},"source":["# Optional Exercise\n","* Experiment with the $K$ parameter of *SGNet*, as well as the rate and  weight_decay paramters of the optimizer to improve the results on the validation set. Finally, check the accuracy on the test set. How does it compare with the results provided in the paper? The results are reproduced below\n","\n","* Do the same for the Citseer and Pubmed citation network datasets\n","\n","* Somethings to try to improve the results:\n","\n","  * Add another convolution layer  \n","  * Add a dropout layer\n","  * Add nonlinearities in the model\n"," \n","  <center><img src=\"https://ai.science/api/authorized-images/fIA50%2BdS0pey1rqtswkEaKhrHMLSGANdEGtf5be8r4ghb15lOoeCRvY2zofkIKqEG5p0%2BwDF1yT2Jii0i%2B58Ffl5jCNDg4vWzlRB9VpDBR%2BI5YKqpeh1Wa7fauh4Y%2FxmNCAF1j8dYdlD%2BcOYSQMLHcZ33QXV1jci0FowIRbCDT0Ax7Jqi8DjR9%2Be9z8ULyDNFjIBb4yKMY3s2qKcHqmulYeTKv9aeYxdrvdD6FsSVaDAo41%2BppCaycng4y0E3j5B591SRLTHnwtjLUEqT3xKeTKJXdgPeOAboibccywv3Jgb3z0X4ztC6DjKOIbSLCWPYKeZMl9SEdhZPMdpROoeEz4aT8BGHdzZojlpO21W3%2BcwvkBGtrV6xH14Jyd6P%2Fcccn9H1pkZjLpNA1vSbhFzMupaHnkFeH8IeJSNMt03Xckj0MXjTBrQsQLy%2FBh2yR%2F4%2B0ZNe%2BvIWHEdbVFqR0j51DTQf2x7cu%2BNJLIQpo8%2F1ipBJRCxTrpWCPM76FODx8qxdZ9ToLDiV7nSuiYBnn9dcdcZMtuAU3LbUoSK8JAuV0wB4Y5d7zSV2w5nfPHZDy4FRy0DGahQjpWujcmsIYqqHl4WpV8pst0lwIcq6uW7%2B5TsbEOHlp11f4vzNGcGJSsErq%2FSBcA9Z7KW9pelss6P8qbcq8gn6B3xC2rs%2ByOorZA%3D\" width=\"80%\" > </center>\n","\n","  \n","\n"]},{"cell_type":"markdown","metadata":{"id":"u1PdH-ZcZby9"},"source":["# References\n","\n"," [Wu, Felix, et al. \"Simplifying graph convolutional networks.\" arXiv preprint arXiv:1902.07153 (2019)](https://arxiv.org/abs/1902.07153)\n","\n","\n"," [Kipf, Thomas N., and Max Welling. \"Semi-supervised classification with graph convolutional networks.\" arXiv preprint arXiv:1609.02907 (2016)](https://arxiv.org/abs/1609.02907)"]}]}