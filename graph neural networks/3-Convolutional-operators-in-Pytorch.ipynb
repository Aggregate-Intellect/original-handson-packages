{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3-Convolutional-operators-in-Pytorch-check-finalrc.ipynb","provenance":[{"file_id":"1RgEtNRK_u2ahmEDA4B5bJkp36f8YmMQi","timestamp":1623016774907},{"file_id":"1rlYsaxugUYBXRGCYWX7yjm73_MZ9bVy7","timestamp":1584936198773}],"collapsed_sections":["pNyBFnssJqZG"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ZTx18D4_Efhb"},"source":["# Convolutional operators in PyG\n","\n","PyG has a lot of useful convolution-like operators already implemented. Moreover, with the  `MessagePassing` Base Class of PyG, it is easy to implement additional operators. In this notebook we will implement the graph convolutional operator from the paper [Semi-Supervised Classification with Graph Convolutional Networks](https://arxiv.org/abs/1609.02907) (Kipf and Welling ICLR 2017). In the process we will be translating equations from the paper into code."]},{"cell_type":"markdown","metadata":{"id":"pNyBFnssJqZG"},"source":["#Installation"]},{"cell_type":"code","metadata":{"id":"NQn2brPUhjQ0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623795255338,"user_tz":240,"elapsed":136656,"user":{"displayName":"Ryan Cohn","photoUrl":"","userId":"01706064865196246875"}},"outputId":"3b45c73f-7832-48d8-e898-fd4ea5ad5ab4"},"source":["!pip uninstall -y torch torchvision torchtext fastai\n","!pip install torch==1.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n","!pip install torch-scatter==latest+cu101 torch-sparse==latest+cu101 -f https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.6.0.html\n","!pip install torch-geometric==1.6.1"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Uninstalling torch-1.8.1+cu101:\n","  Successfully uninstalled torch-1.8.1+cu101\n","Uninstalling torchvision-0.9.1+cu101:\n","  Successfully uninstalled torchvision-0.9.1+cu101\n","Uninstalling torchtext-0.9.1:\n","  Successfully uninstalled torchtext-0.9.1\n","Uninstalling fastai-1.0.61:\n","  Successfully uninstalled fastai-1.0.61\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.6.0+cu101\n","\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.6.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (708.0MB)\n","\u001b[K     |████████████████████████████████| 708.0MB 30kB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0+cu101) (1.19.5)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0+cu101) (0.16.0)\n","Installing collected packages: torch\n","Successfully installed torch-1.6.0+cu101\n","Looking in links: https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.6.0.html\n","Collecting torch-scatter==latest+cu101\n","\u001b[?25l  Downloading https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.6.0/torch_scatter-latest%2Bcu101-cp37-cp37m-linux_x86_64.whl (11.5MB)\n","\u001b[K     |████████████████████████████████| 11.5MB 9.7MB/s \n","\u001b[?25hCollecting torch-sparse==latest+cu101\n","\u001b[?25l  Downloading https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.6.0/torch_sparse-latest%2Bcu101-cp37-cp37m-linux_x86_64.whl (23.0MB)\n","\u001b[K     |████████████████████████████████| 23.0MB 1.3MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse==latest+cu101) (1.4.1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse==latest+cu101) (1.19.5)\n","Installing collected packages: torch-scatter, torch-sparse\n","Successfully installed torch-scatter-2.0.5 torch-sparse-0.6.8\n","Collecting torch-geometric==1.6.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/67/6c0bce6b6e6bc806e25d996e46a686e5a11254d89257983265a988bb02ee/torch_geometric-1.6.1.tar.gz (178kB)\n","\u001b[K     |████████████████████████████████| 184kB 13.6MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.6.1) (1.6.0+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.6.1) (1.19.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.6.1) (4.41.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.6.1) (1.4.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.6.1) (2.5.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.6.1) (0.22.2.post1)\n","Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.6.1) (0.51.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.6.1) (2.23.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.6.1) (1.1.5)\n","Collecting rdflib\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n","\u001b[K     |████████████████████████████████| 235kB 21.3MB/s \n","\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.6.1) (3.1.0)\n","Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.6.1) (0.4)\n","Collecting ase\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/36/de17e79f29e06d9a92746d0dd9ec4636487ab03f6af10e78586aae533f7a/ase-3.21.1-py3-none-any.whl (2.2MB)\n","\u001b[K     |████████████████████████████████| 2.2MB 28.7MB/s \n","\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.6.1) (2.11.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch->torch-geometric==1.6.1) (0.16.0)\n","Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->torch-geometric==1.6.1) (4.4.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric==1.6.1) (1.0.1)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->torch-geometric==1.6.1) (0.34.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->torch-geometric==1.6.1) (57.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==1.6.1) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==1.6.1) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==1.6.1) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==1.6.1) (1.24.3)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric==1.6.1) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric==1.6.1) (2.8.1)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric==1.6.1) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric==1.6.1) (1.15.0)\n","Collecting isodate\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n","\u001b[K     |████████████████████████████████| 51kB 5.5MB/s \n","\u001b[?25hRequirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->torch-geometric==1.6.1) (1.5.2)\n","Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ase->torch-geometric==1.6.1) (3.2.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric==1.6.1) (2.0.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric==1.6.1) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric==1.6.1) (1.3.1)\n","Building wheels for collected packages: torch-geometric\n","  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-geometric: filename=torch_geometric-1.6.1-cp37-none-any.whl size=308564 sha256=91b7bcbc2f5ae3b792409102e3298b368b3ef31778802d1aa8955bf87fbdb2ea\n","  Stored in directory: /root/.cache/pip/wheels/e6/25/ea/3d71d2088dccc63214fa59259dcc598ded4150a5f8b41d84ff\n","Successfully built torch-geometric\n","Installing collected packages: isodate, rdflib, ase, torch-geometric\n","Successfully installed ase-3.21.1 isodate-0.6.0 rdflib-5.0.0 torch-geometric-1.6.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"E9fFX-36vfrw"},"source":["# Graph-Network Block\n","\n","A general way to express convolution-like operators on graphs is by using a message-passing framework described in\n","[Battaglia, Peter W., et al. \"Relational inductive biases, deep learning, and graph networks.\"]( https://arxiv.org/pdf/1806.01261.pdf). In this framework, a convolution-like operator applied to a graph consists of the following steps:\n","\n","\n","1.  For each edge $e_k=(v_{s_k}, v_{r_k})$  which starts at node $v_{s_k}$ and ends at node $v_{r_k}$, <sup>[*](#myfootnote1)</sup>  we compute an (updated) edge feature-vector \n","$$ \\mathbf{e}_k^\\prime = \\phi^e\\left(\\mathbf{e}_k, \\mathbf{v}_{s_k}, \\mathbf{v}_{r_k}\\right),$$ \n","where $\\mathbf{v}_{s_k}$ is the initial feature vector of node $v_{s_k}$,  $\\mathbf{v}_{r_k}$ is the initial feature vector of node $v_{r_k}$, and $\\mathbf{e}_k$ is the initial feature vector of edge $e_k.$ The updated edge feature vector  will be passed to node  $v_{r_k}$ as a message. \n","The function $\\phi^e$ can be any differentiable function such as a multi-layer perceptron or a simple linear function. \n","\n","<center>\n","<img src=\"https://ai.science/api/authorized-images/HzNp9jfkWd9u2Mi4WPB8Yyux4ayT2%2B0ywDOVoSDzXECYMfdaH%2B8JA8Cj4g18CiAtxl2tnuIQeK8RUpgqA03QMu2LiYKAOrVqNnFq%2Fc9EWKnFR0DDejFabHGh0sM5J%2FlLVGA88L9ZPZLD3LPJNLJN4rrsdqCJQOWwUiupBlmOHY2bc4xG5fwvdh5l8xy81betZCZrIzZR6nqBMtb7PKOz9%2BF88IHUbCkK99YZau079WGzkd0IX8t67kJpZuiD4rFQQPMYaN2WUBJyn8RnDsntlsIkeYS10jDbvNRuHNkrAU5SY%2FiPBTnhDUyMLrmMViI24WOAy2v1r4wrWDf5kjpTgDaV09RjXNFMj8MRqnEAHtnWRtBCGsbmZFoWmNrFo0YyuGUP%2BxydbkHuzXxTdEhW6FrsGvxGPDap0OGoVfneXPZ87kic1fYS8P3Qv65VgTk%2FNHXWeXhTLN9Y4hbpCOTaaIXJpYJaPPNofuDGQJK2zbPVFv6elUtNY2wwgDt%2F60KfWSdopVF9xqTB1twzLoqru7nfYN%2BhrGlohwn425rBk%2BR1FZpAxX8MoRtycuykiPhxsHJN9obSsPCRk1nswRMtXJRoe5UnoCrCXpwu0jHq%2F64l45XLfFC%2FKwWFAYyyY7Xr2VbqYJh374zEO47S08Ead1c0y27zkVSdQftaw1ZJibk%3D\" width=\"40%\" > </center>\n","\n","\n","2. Once all the messages are computed, all incoming messages to a given node $v_i$ are aggregated by a permutation-invariant operator \n","$\\rho^{e\\rightarrow v}$ \n","to compute a single aggregated message $\\bar{\\mathbf{e}}_i^\\prime$ for node $v_i$,\n"," where\n","$$ \\bar{\\mathbf{e}}_i^\\prime = \\rho^{e\\rightarrow v}(\\{\\mathbf{e}_k^\\prime\\}_{r_k=i}). $$ \n","Here, $\\{\\mathbf{e}_k^\\prime\\}_{r_k=i}$ is the set of all incoming messages from edges that end at node $v_i$. We stress here that the function $\\rho^{e\\rightarrow v}$  should take an arbitrary number of arguments (because a node can have an arbitrary number of neighbors) and be permutation invariant (because a node's neighbors do not have any natural ordering).  Examples of permutation-invariant operator are\n","`sum`, `mean`, `max`, `min`, and `softmax`. \n","It is important that the operator is permutation invariant because the incoming messages to a node have no natural ordering.\n","\n","\n","<center>\n","<img src=\"https://ai.science/api/authorized-images/Zs594R5Id36UdAwRFxSDGUv0Xc09IYGZ4%2BNmsHXffKW%2Bo1t6tRTvAunyORISMAEQKUCWIkrXap%2B1Jrr6cHGrXGcnNGiTuuSplHi6szdstTRtpz9r1S9jGT4MjdBdCJMT%2BcWmSzFWe2Nbxt7CZCiC%2BWRXhtlHmE7kdQhuKmkPxuJI6G7qVa7KCPxWj43I7aBdfSLBmAlf36qn4oaGAUmp%2FuoOtEnAnjgSwVJoCCSZlpSfjzsLy%2Bp26R69Ltr9e1MXax1OChGc4Aco%2BvfPbx1Dt29ayGCJhRJQ0h6XqfXFq87gQSMTMe852ftzx%2Bo5xIcpOJjD2sZwDG%2Bjsk2Kdwr9ZiKUetHAU1yOk%2BvgeRzIxuOw4znbcacTN0gjxMT0l6rTl09o4ueX6dGh9JNC0loidSpo1qC6CqOLlKefnjMsz5joSk0xOc2fvFc38rzgSqVk7zjEvf8KEoKENKYQjTdA6wxdYHoeol0ugHSPf7Kk42l0E4%2FqNmBm8Lv9%2BXYjHumkXPoVqQdGTxk7vJlGT5k5%2F7qUuboCheHhPbnfdybtSILTJ8wYUKjXybJ1DjXw3%2BBsCFZEhkqj39LFDQBKriKAaaQqxtX6M1iw%2B8uZoo9XZQNZlK2amPiA27z8eDWlCv09gP%2BN9KPWrBN8i1a04sR8FRubm90fw4nkIEKi9FdPIAU%3D\" width=\"40%\" > </center>\n","\n","\n","\n","3. Finally the aggregated message $ \\bar{\\mathbf{e}}_i^\\prime$ can be used to compute an updated feature vector for node $v_i$ for the next layer or to be used for a downstream task:\n","$$ \\mathbf{v}_i^\\prime = \\phi^v\\left(\\bar{\\mathbf{e}}_i^\\prime, \\mathbf{v}_i \\right)$$\n","where $\\phi^v$ is any differentiable  function.\n","\n","<center>\n","<img src=\"https://ai.science/api/authorized-images/0C4kMtUxFY3jcOh4F6mtIAO4n2GR9aNZ%2BtJuecObzsJSEPJYKE7ljsswtSCKxc7GoSH64LU5Z%2BO7AtEkQ6Jkpm4hpvjfrRLJSgbf3lyS1YMxsFbBYT7TaCQPcfxYonNWEcC%2FEKQHtlXsbfzgdhxdRuNLuIiHU3wtHcQ9LA7XMXAkNR8yR1Zd%2FYO%2Fr85l0hXKc9mhmZDmGato56E7kAga23mLpNBHo42Trtt4mq%2Bn5%2Fma5QzT0KGW1XjrFM%2BAeqnr1L%2Fr8a4I6lfUUfoa9LNog5s9Ln3KL7DY0C2p1DrQb9mOmmaMkjJ4ArKpyx6jshV4vAdI9FZNvzai8AvTxd4Wr7hIhIN%2FW1HzrOpv1RfDqh5hI%2FwVMORUz51PoeYhggVoMZnqxTMbQNWOPAJaorxL7lfcXkmjpdUI9RawmjBUJ3wI8PVVqpeE%2BeWTShK3jYuCKHX51frjOBpQq6uzfh6cGALEcoUvdTUhBu0hNYE0dgXV%2Fn8lGte%2FrtcaRVqkFpJ1k0e5g9jzXHd4NV5okfpTLELevii5sHHc%2B8%2BJQmvjKAJgbxWvzE1BFXx6NUWH1ZpdAvmqaoRNgpCMZhb%2FHVlLbb%2Fia3zTFZgpZ%2FImCjXx6pQmi5I%2Fr603AsHbwIuHpvkUTWJNoxT%2FRsY%2BBd%2BfldYelZU4Fjwu2cnzUL5keAPZM8I%3D\" width=\"40%\" > </center>\n","\n","\n","\n","Note: For simplicity, the treatment of the feature vector of the graph itself $\\mathbf{u}$ has been omitted above.\n","\n","Steps 1-3 form one GN block. The output of this block is the updated edge and node feature-vectors. These updated feature-vectors can be passed on to another block.\n","\n","\n","\n","<a name=\"myfootnote1\">*</a>: Note: the letter *r* is for receiver and the letter *s* is for sender\n"]},{"cell_type":"markdown","metadata":{"id":"xa3DfpJ7JxlC"},"source":["# Implementation of Graph Convolutional Network (Kipf et al 2017)"]},{"cell_type":"markdown","metadata":{"id":"C3TZAIIoNVB8"},"source":["We will implement the graph convolutional operator described in [Kipf and Welling ICLR 2017](https://arxiv.org/abs/1609.02907)\n","\n","The convolution operator can be written as\n","\n","$$\\mathbf{v}_i^{\\prime} = \\sum_{j \\in \\mathcal{N}(i) \\cup i}^{n}  \\frac{1}{\\sqrt{(d_i+1)(d_j+1)}}\\Theta \\mathbf{v}_j,$$ \n","where $\\mathcal{N}(i)$ are the neighboring node-indices of node $v_i$,  $d_i$ is the degree (number of neighbors) of node $v_i$, and $\\Theta$ is a learnable tensor.\n","\n","\n","In terms of the message passing framework described above  <sup>[*](#myfootnote1)</sup>, the message  $\\phi^e$ function (which doesn't use any edge features in this case) is \n","\n","$$\\phi^e\\left(\\mathbf{v}_i, \\mathbf{v}_j\\right) = \\frac{1}{\\sqrt{(d_i+1)(d_j+1)}}\\Theta\\mathbf{v}_j. $$ \n","\n","The aggregation operator is the `sum` operator $ \\sum$ i.e.:\n","$$ \\rho^{e\\rightarrow v}(\\{\\mathbf{e}_k^\\prime\\}_{r_k=i})=  \\sum(\\{\\mathbf{e}_k^\\prime\\}_{r_k=i})$$\n","and the update operator $\\phi^v$ is given by\n","\n","$$\\phi^v\\left(\\bar{\\mathbf{e}}_i^\\prime, \\mathbf{v}_i \\right)= \\frac{1}{1+d_i}\\Theta\\mathbf{v}_i + \\bar{\\mathbf{e}}_i^\\prime.$$\n","\n","\n","<a name=\"myfootnote1\">*</a>: Note: The Message Passing framework was initially described in  [Gilmer et al., 2017 ](https://arxiv.org/abs/1704.01212). The paper [Kipf and Welling ICLR 2017](https://arxiv.org/abs/1609.02907) does not use this terminology.\n"]},{"cell_type":"markdown","metadata":{"id":"p9P5Uq93fIV_"},"source":["Let's see how this can be implemented in PyG.\n","We will define our `MyGCNConv` class, which inherets from the \n","`MessagePassing` Base Class, which itself inherets from `torch.nn.Module`.\n","In addition to the usual forward() function, we need to define \n","message() and update() functions.\n","\n","See [here](https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html) for more details on the `MessagePassing` Base Class\n"]},{"cell_type":"code","metadata":{"id":"T6vitSVEPm0Y","executionInfo":{"status":"ok","timestamp":1623795262420,"user_tz":240,"elapsed":7088,"user":{"displayName":"Ryan Cohn","photoUrl":"","userId":"01706064865196246875"}}},"source":["import torch\n","from torch_geometric.nn import MessagePassing\n","from torch_geometric.utils import add_self_loops, degree\n","\n","\n","class MyGCNConv(MessagePassing):\n","\n","    # 0 - Instantiation of class. Here the linear operator is defined according\n","    # to the arguments in_channels and out_channels\n","    def __init__(self, in_channels, out_channels):\n","\n","        # Define the aggregation function used to aggregate \n","        #all messages passed into a node\n","        super().__init__(aggr='add') \n","\n","        # Linear layer to transform feature vector of a neighboring node\n","        # from length in_channels to length out_channels\n","        self.lin = torch.nn.Linear(in_channels, out_channels,bias=False)\n","\n","    # 1 - The forward function is first called when a user calls an instance\n","    # of MyGCNConv. By PyG's convention, the feature vector is denoted by x. \n","    def forward(self, x, edge_index):\n","        # x: node features. Shape:  (N, in_channels)\n","        # edge_index: graph structure. Shape: (2, E)\n","\n","        # Transform the feature vectors of all nodes. \n","        # Output Shape: (N, out_channels)\n","        x = self.lin(x) # Note this gives \\Theta * V\n","\n","        # rows is the source-node indices and cols contains the receiver-node indices\n","        rows, cols = edge_index \n","\n","        # Compute degree (i.e. number of neighbors) of each node\n","        degrees = degree(rows, dtype=x.dtype) # Shape:(N)\n","        degrees = degrees.view(-1,1) # Shape (N,1)\n","\n","        # We are now ready to call the propagate function defined in the base class,\n","        # which takes in the edge indices (graph structure) and additional data.\n","        # The propagate function first calls the message function (defined below).\n","        # After the message is built, the propagate function then aggregates \n","        # the messages according the operator defined in the call to \n","        # super().__init__ (see above). Finally the propagate function calls \n","        # the update function (defined below).\n","        # The user can specify here which variables to pass on to \n","        # both the message and update functions \n","        return self.propagate(edge_index, size=(x.size(0), x.size(0)), \n","                              x=x, degrees=degrees)\n","\n","    # The message function computes the message for each edge. \n","    # The arguments provided to the propagate function can be accessed here.\n","    # The suffices \"_i\" and \"_j\" can be used to map any node features to the \n","    # source and destination nodes,respectively, of the edges in the graph.\n","    def message(self, x_j, degrees_i, degrees_j):\n","        # x_j:features of the source node for each edge. Shape: [E, out_channels] \n","        # degrees_j:degree of the source node for each edge. Shape: [E, 1]\n","        # degrees_i:degree of the destination node for each edge. Shape: [E, 1]\n","        norm = ((degrees_j+1).pow(-0.5)*(degrees_i+1).pow(-0.5))\n","\n","        # Construct the message\n","        return norm*x_j\n","\n","    # The update function. Takes the output of the aggregate function.\n","    # The arguments in the propagate function can also be accessed here\n","    def update(self, aggr_out, x, degrees):\n","        # aggr_out has shape [N, out_channels]\n","        # x has shape [N, out_channels]\n","        # degrees has shape [N, out_channels]\n","        x_new = aggr_out +x/(degrees+1)\n","        return x_new"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iN_rYmSlJ-s9"},"source":["# Optional Exercises:\n","\n","Exercise 1: Write a Graph Neural Network which uses the GCN Operator above.\n","\n","Exercise 2: Train the Network in Exercise 1 for a node classification task.\n","\n","Exercise 3: Try modifying different aspects of the network above (e.g. normalization factor, bias in the linear layer or in the update step), and see how it affects the accuracy of the task in Exercise 2"]}]}