{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Statistical_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FraJTHidSHaE"
      },
      "source": [
        "# Statistical NLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shOVWkYJSnRK"
      },
      "source": [
        "## News Categorization\n",
        "Let's write an algorithm that automatically categorizes news types."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8uwkE5OKyVM"
      },
      "source": [
        "# Let's select the categories we'd like to exist in our dataset\n",
        "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkNlGjaVTPjV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c55783cf-047c-452b-f27e-e444c4b668ea"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42) # getting the data, randomly shuffling the dataset"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsiIIu_HTUe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ad9348d-5348-4879-e4d0-21cd9149dcac"
      },
      "source": [
        "twenty_train.target_names # chekcing if the dataset has our categories as its target"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unq6eyxjUB9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e69a390b-c803-43e2-85f1-ee2cb7a6844c"
      },
      "source": [
        "# size of the training data\n",
        "len(twenty_train.data)\n",
        "len(twenty_train.filenames)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2257"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP4eZGlxUMqZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70cb0f22-dd0e-4ee6-f015-4f09eb092ee1"
      },
      "source": [
        "# let's take a look at the initial lines of a datapoint\n",
        "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")[:3]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: sd345@city.ac.uk (Michael Collier)\n",
            "Subject: Converting images to HP LaserJet III?\n",
            "Nntp-Posting-Host: hampton\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-jsZ3dvUcP-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "720b2be0-bf31-411a-9933-1913cf9467b9"
      },
      "source": [
        "# fetching the categoty of the first datapoint in the training data\n",
        "twenty_train.target_names[twenty_train.target[0]]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'comp.graphics'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjLE5HcZVGbo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba984762-72a9-4660-8b53-7db8f9f1b815"
      },
      "source": [
        "# let's see the targets:\n",
        "twenty_train.target[:10] # these are the numerical representations of each news category correspondind with your dataset"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 3, 3, 3, 3, 3, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGd1iueQV4jc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b36c90a-5d98-4237-9216-41359a4566ca"
      },
      "source": [
        "# now let's see target names corresponding to these numeric categories\n",
        "for t in twenty_train.target[:10]:\n",
        "  print(twenty_train.target_names[t])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "comp.graphics\n",
            "comp.graphics\n",
            "soc.religion.christian\n",
            "soc.religion.christian\n",
            "soc.religion.christian\n",
            "soc.religion.christian\n",
            "soc.religion.christian\n",
            "sci.med\n",
            "sci.med\n",
            "sci.med\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N38puyfTWRre"
      },
      "source": [
        "## Bag of Words\n",
        "Bag of words representation is a powerful feature representation for text classification expecially when the sequence is short. \n",
        "\n",
        "Watch out: the vectors can get very big, since they can correspond to the entire vocabulary. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGOU6CcoWx4D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "099c27a5-be76-449a-8aac-618970cc59bd"
      },
      "source": [
        "# tokenizing with scikit-learn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
        "X_train_counts.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2257, 35788)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY4azMe-X44x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "949ba8ca-8af0-4e39-ea63-50afc54c5da0"
      },
      "source": [
        "# getting the index of a vocabulary item\n",
        "count_vect.vocabulary_.get(u'algorithm')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4690"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aULW_rP9LJs8"
      },
      "source": [
        "## TF-IDF: Avoiding the frequency effect "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgfVCbbvLlHB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e322f318-9360-44c8-e86e-9721217d3287"
      },
      "source": [
        "# term frequency matrix\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
        "X_train_tf = tf_transformer.transform(X_train_counts)\n",
        "X_train_tf.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2257, 35788)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftjntDTzLtAY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e5e0889-3d57-485c-98ab-43f3fb496c52"
      },
      "source": [
        "# TF-IDF matrix\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "X_train_tfidf.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2257, 35788)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFlBilvRNTnO"
      },
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBlye0M1Natm"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvEsvmlXNdym"
      },
      "source": [
        "# picking a classifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1DsFdcHNl0s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a561700a-d3b2-4545-ab85-65566c1eb5a4"
      },
      "source": [
        "# Inference using the trained classifier\n",
        "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
        "X_new_counts = count_vect.transform(docs_new)\n",
        "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
        "\n",
        "predicted = clf.predict(X_new_tfidf)\n",
        "\n",
        "for doc, category in zip(docs_new, predicted):\n",
        "  print('%r => %s' % (doc, twenty_train.target_names[category]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'God is love' => soc.religion.christian\n",
            "'OpenGL on the GPU is fast' => comp.graphics\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZJ1Kxt9N4op"
      },
      "source": [
        "## Building an ML Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_CqhOwMOOxF"
      },
      "source": [
        "# building the pipeline object. The keys are useful for parameter tuning\n",
        "from sklearn.pipeline import Pipeline\n",
        "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB()),])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTNyWN3EO3_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8234a824-2306-45ca-e755-46461fdcc6fa"
      },
      "source": [
        "# training using the pipeline object\n",
        "text_clf.fit(twenty_train.data, twenty_train.target)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('tfidf',\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxkagHeHYPds"
      },
      "source": [
        "## Evaluating a Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZwRqTYgW7zm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d45c775c-1e34-4550-eaf1-f973bad816a6"
      },
      "source": [
        "# testing the model performance\n",
        "import numpy as np\n",
        "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
        "docs_test = twenty_test.data\n",
        "predicted = text_clf.predict(docs_test)\n",
        "np.mean(predicted == twenty_test.target)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8348868175765646"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhPfIVCkYZXh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff4efd74-2401-4d9f-d9cd-ba552bcf9339"
      },
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.classification_report(twenty_test.target, predicted, target_names=twenty_test.target_names))\n",
        "metrics.confusion_matrix(twenty_test.target, predicted)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "           alt.atheism       0.97      0.60      0.74       319\n",
            "         comp.graphics       0.96      0.89      0.92       389\n",
            "               sci.med       0.97      0.81      0.88       396\n",
            "soc.religion.christian       0.65      0.99      0.78       398\n",
            "\n",
            "              accuracy                           0.83      1502\n",
            "             macro avg       0.89      0.82      0.83      1502\n",
            "          weighted avg       0.88      0.83      0.84      1502\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[192,   2,   6, 119],\n",
              "       [  2, 347,   4,  36],\n",
              "       [  2,  11, 322,  61],\n",
              "       [  2,   2,   1, 393]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZs8xqvqbARN"
      },
      "source": [
        "## Parameter Tuning: Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSGKJjsQbP8B"
      },
      "source": [
        "# defining the grid\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False), 'clf__alpha': (1e-2, 1e-3),}"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PPgF6tybZzI"
      },
      "source": [
        "# using all the CPUs\n",
        "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9whI7pxIbaNd"
      },
      "source": [
        "# picking a smaller subset of the data just for illustration purposes. In real world scenario's it's essential to tune the parameters on the entire training set.\n",
        "# training the grid-search-optimized classifier on the subset and storing the model in memory \n",
        "gs_clf = gs_clf.fit(twenty_train.data[:400], twenty_train.target[:400])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia-NjUntcL9Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e5b5c3c6-5933-413a-c055-cff506a714c1"
      },
      "source": [
        "\n",
        "twenty_train.target_names[gs_clf.predict(['God is love'])[0]]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'soc.religion.christian'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gunsnt1VdkFN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c9d664b-5988-49f5-d3ff-ea0ef049a0eb"
      },
      "source": [
        "# the best parameter set and score are accessible to retrieve\n",
        "print(gs_clf.best_score_)\n",
        "for param_name in sorted(parameters.keys()):\n",
        "  print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9349999999999999\n",
            "clf__alpha: 0.01\n",
            "tfidf__use_idf: True\n",
            "vect__ngram_range: (1, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSheGqKhXGpe"
      },
      "source": [
        "# Exercise 4\n",
        "## 1. Try the experiment using a different classifier. Did the results improve? Can you reason why?\n",
        "## 2. Use word embeddings instead of tf-idf vectors and retrain your classifier. Do the resuslts improve? \n",
        "## --Hint: tf-idf vectors represent documents. Vanilla word embeddings represent words. A simple way to create word embeddings of an entire document is to average all the words. It's a good practice to filter out functions words (to, at, is, with, etc.) since they do not have substantial semantics associated with them.\n",
        "\n"
      ]
    }
  ]
}