{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "c_AISC_Math Session5_Book5_sol.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "org": null
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lIvbPd7lhyg"
      },
      "source": [
        "## Fit a function with PyTorch Backpropagation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqyrFKxXlhzt"
      },
      "source": [
        "Let's pick a simple function $y$ defined as \\\\\n",
        "$y = 2x$ \\\\\n",
        "and generate a sample data:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX53gVHIlh0K"
      },
      "source": [
        "from pylab import *\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "#Create sample data\n",
        "x = [1.0, 2.0, 3.0]\n",
        "y = [2*xx for xx in x]"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQSeUCBnDhTo"
      },
      "source": [
        "Notice that we are setting True on the ``requires_grad`` parameter. In Pytorch, each tensor has this parameter available since this enable to track the gradients across the network. Here it's in-depth explanation of what requires_grad enables: https://www.youtube.com/watch?v=MswxJw-8PvE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjk80ajiDhTq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "91de0f81-7b3c-4044-9438-b530c7cf343d"
      },
      "source": [
        "data = {'x':x, 'y':y}\n",
        "df = pd.DataFrame(data=data, index=x)\n",
        "print(\"Training Data:\")\n",
        "df"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       x    y\n",
              "1.0  1.0  2.0\n",
              "2.0  2.0  4.0\n",
              "3.0  3.0  6.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdD-oRQJlh0S"
      },
      "source": [
        "Now let's pretend we don't know the generating function $y$. All we know\n",
        "about it is that $y$ is a linear function. So we can write it as:\n",
        "\n",
        "$y_{pred} = w*x$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3t0PP4clh0Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b3cbc17-df77-443e-f56a-1030b5429601"
      },
      "source": [
        "w = Variable(torch.Tensor([1.0]),  requires_grad=True)  # Any random value for weights\n",
        "print(\"Random initial value for w:\", w.data[0])\n",
        "\n",
        "# our model forward pass\n",
        "# this is actually our y_pred as we defined above\n",
        "def forward(x):\n",
        "    return x * w"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random initial value for w: tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJXYW65zlh0a"
      },
      "source": [
        "**Goal**: use the training data above to find the parameter $w$.\n",
        "\n",
        "**Solution:** Loss function for our problem is: \\\\\n",
        "$loss(w) = (y_{pred}-y)^2$\n",
        "\n",
        "Remembering the definition of $y_{pred} = w*x$ we can rewrite the loss function as \\\\\n",
        " $loss(w) = ( w*x-y)^2$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mOAoGNdInIv"
      },
      "source": [
        "# Define loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nsbSvCtlh0b"
      },
      "source": [
        "# Loss function\n",
        "def loss(x, y):\n",
        "    y_pred = forward(x)\n",
        "    return (y_pred - y) * (y_pred - y)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGJsYoXFlh0c"
      },
      "source": [
        "To minimize the loss, we should compute the derivative of loss wrt $w$\n",
        "and interatively change $w$ to move in the direction of the descent:\n",
        "\n",
        "![img](http://donsoft.io/deep-learning-with-rnns/images/gradient_descent_cropped.gif \"alt text\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T9fj8AdL1_q"
      },
      "source": [
        "# Calculate gradient\n",
        "\n",
        "Derivative of loss with respect to $w$ is automatically computed by\n",
        "PyTorch using *autograd* and will be kept automatically in\n",
        "\n",
        "    w.grad.data\n",
        "\n",
        "before we start training let's see how our predictions look with the\n",
        "arbitrary weight $w=1$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwlLKfCTJJv8"
      },
      "source": [
        "#Before training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY16lDPglh0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88ce2c03-6b02-4d72-9620-f3a520aae075"
      },
      "source": [
        "# predict the value of the predicted function at x = 4 before training\n",
        "# Before training\n",
        "print(\"predict (before training)\")\n",
        "print(\"input: 4\")\n",
        "print(\"model prediction (before training): \", forward(4).data[0], \" -- correct answer: 2x4 = 8\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predict (before training)\n",
            "input: 4\n",
            "model prediction (before training):  tensor(4.)  -- correct answer: 2x4 = 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9cBYK9Xlh0m"
      },
      "source": [
        "##### Visualize training data vs predicted function values, before training:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFG9rvUZlh0n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "9ebbc133-2ea6-4839-9ab8-25040b130564"
      },
      "source": [
        "x_data = df['x']\n",
        "y_data = df['y']\n",
        "plot(x_data,y_data,'ro', label=\"Training Data\")\n",
        "plot(x_data,[forward(x) for x in x_data], label=\"Model Prediction before training\")\n",
        "legend()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc6b39691d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snL3zWdvJ-d0"
      },
      "source": [
        "#Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08C71J5Rlh0p"
      },
      "source": [
        "That's pretty bad! Let's learn the predicting function $y_pred$ by\n",
        "learning the value of $w$.\n",
        "\n",
        "We will move $w$ according to this rule: \\\\\n",
        "$w = w - learning\\_rate * grad$\n",
        "\n",
        "where\n",
        "\n",
        "    grad = w.grad.data[0]\n",
        "\n",
        "Remember in Pytorch we can call the ``.backward()`` method on tensors and take the derivative with respect of every parameter which has ``requires_grad = True`` \n",
        "\n",
        "Let's pick a small step size as our learning rate:\n",
        "\n",
        "$learning\\_rate = 0.01$\n",
        "\n",
        "and solve the problem using gradient descent in 10 iterations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC3q0rsklh0s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7895a4e3-1486-43a8-9e8b-f2bea8e3a225"
      },
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(10): #n_epochs (aka iterations) are 10\n",
        "    for x_val, y_val in zip(x_data, y_data):\n",
        "        #compute loss for this step\n",
        "        l = loss(x_val, y_val)\n",
        "        #backprop\n",
        "        l.backward() \n",
        "        # grad is automatically computed\n",
        "        print(\"\\tgrad: \", x_val, y_val, w.grad.data[0])\n",
        "        # alter w for this step \n",
        "        w.data = w.data - learning_rate * w.grad.data\n",
        "\n",
        "        # Manually zero the gradients after updating weights\n",
        "        w.grad.data.zero_()\n",
        "\n",
        "    print(\"progress:\", epoch, l.data[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tgrad:  1.0 2.0 tensor(-2.)\n",
            "\tgrad:  2.0 4.0 tensor(-7.8400)\n",
            "\tgrad:  3.0 6.0 tensor(-16.2288)\n",
            "progress: 0 tensor(7.3159)\n",
            "\tgrad:  1.0 2.0 tensor(-1.4786)\n",
            "\tgrad:  2.0 4.0 tensor(-5.7962)\n",
            "\tgrad:  3.0 6.0 tensor(-11.9981)\n",
            "progress: 1 tensor(3.9988)\n",
            "\tgrad:  1.0 2.0 tensor(-1.0932)\n",
            "\tgrad:  2.0 4.0 tensor(-4.2852)\n",
            "\tgrad:  3.0 6.0 tensor(-8.8704)\n",
            "progress: 2 tensor(2.1857)\n",
            "\tgrad:  1.0 2.0 tensor(-0.8082)\n",
            "\tgrad:  2.0 4.0 tensor(-3.1681)\n",
            "\tgrad:  3.0 6.0 tensor(-6.5580)\n",
            "progress: 3 tensor(1.1946)\n",
            "\tgrad:  1.0 2.0 tensor(-0.5975)\n",
            "\tgrad:  2.0 4.0 tensor(-2.3422)\n",
            "\tgrad:  3.0 6.0 tensor(-4.8484)\n",
            "progress: 4 tensor(0.6530)\n",
            "\tgrad:  1.0 2.0 tensor(-0.4417)\n",
            "\tgrad:  2.0 4.0 tensor(-1.7316)\n",
            "\tgrad:  3.0 6.0 tensor(-3.5845)\n",
            "progress: 5 tensor(0.3569)\n",
            "\tgrad:  1.0 2.0 tensor(-0.3266)\n",
            "\tgrad:  2.0 4.0 tensor(-1.2802)\n",
            "\tgrad:  3.0 6.0 tensor(-2.6500)\n",
            "progress: 6 tensor(0.1951)\n",
            "\tgrad:  1.0 2.0 tensor(-0.2414)\n",
            "\tgrad:  2.0 4.0 tensor(-0.9465)\n",
            "\tgrad:  3.0 6.0 tensor(-1.9592)\n",
            "progress: 7 tensor(0.1066)\n",
            "\tgrad:  1.0 2.0 tensor(-0.1785)\n",
            "\tgrad:  2.0 4.0 tensor(-0.6997)\n",
            "\tgrad:  3.0 6.0 tensor(-1.4485)\n",
            "progress: 8 tensor(0.0583)\n",
            "\tgrad:  1.0 2.0 tensor(-0.1320)\n",
            "\tgrad:  2.0 4.0 tensor(-0.5173)\n",
            "\tgrad:  3.0 6.0 tensor(-1.0709)\n",
            "progress: 9 tensor(0.0319)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4KoGErmMF4v"
      },
      "source": [
        "#After learning\n",
        "#### Let's see how well we are doing in prediction a single value of the function after training for 10 steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNrFVvtolh0t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16efcf77-479f-46ce-95f4-3e65abaec890"
      },
      "source": [
        "# After training\n",
        "print(\"predict (after training)\")\n",
        "print(\"input: 4\")\n",
        "print(\"model prediction (after training): \", forward(4).data[0], \" -- correct answer: 8\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predict (after training)\n",
            "input: 4\n",
            "model prediction (after training):  tensor(7.8049)  -- correct answer: 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy_kdxJQlh2f"
      },
      "source": [
        "#### Looks really promising! Let's look at the predicted function over all values in the training range:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duiXJ1Lelh2h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "f3627b23-3ca9-46cc-e71e-519d297cc8e3"
      },
      "source": [
        "plot(x_data,y_data,'ro', label=\"Training Data\")\n",
        "plot(x_data,[forward(x) for x in x_data], label=\"Model Prediction after training\")\n",
        "legend()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc6b33ecb90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbx0nlDElh2k"
      },
      "source": [
        "Hoorray! We have learned the desired function at a pretty good accuracy!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2Xxp0jYlh2p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad9829d2-5b70-46da-ec05-8cfe93080266"
      },
      "source": [
        "print(\"Learned function:\")\n",
        "print(\"y_pred = %f * x\"%w )"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learned function:\n",
            "y_pred = 1.951216 * x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJqVHpQYlh2q"
      },
      "source": [
        "## Exercise I:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-Rih5cSlh2u"
      },
      "source": [
        "Repeat the above exercise for\n",
        "\n",
        "$y = x^2$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iGwDLSQLkOz",
        "outputId": "c5be9394-689d-44c8-bccf-b0ea23f56b44"
      },
      "source": [
        "# We know our model is non-linear\n",
        "w = Variable(torch.Tensor([3.0]),  requires_grad=True)  # Any random value for weights\n",
        "print(\"Random initial value for w:\", w.data[0])\n",
        "\n",
        "# our nmodel forward pass\n",
        "# this actually our y_pred aswe defined above\n",
        "def nforward(x):\n",
        "  return x**w"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random initial value for w: tensor(3.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARdLFTB5N0VB"
      },
      "source": [
        "#Define *loss* function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SHmXoLqOBfg"
      },
      "source": [
        "import numpy as np\n",
        "# Loss function\n",
        "def nloss(x,y):\n",
        "  y_pred=nforward(x)\n",
        "  return (y_pred-y)*(y_pred -y)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ILTyz3xSREJ"
      },
      "source": [
        "### Generate data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoPyHlOOR5Ol",
        "outputId": "3bfbde8f-7c86-45e3-9109-4f953a535815"
      },
      "source": [
        "x = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]\n",
        "y = [xx**2 for xx in x]\n",
        "\n",
        "data = {'x':x, 'y':y}\n",
        "df = pd.DataFrame(data=data, index=x)\n",
        "print(\"Training Data:\")\n",
        "x_data = df['x']\n",
        "y_data = df['y']\n",
        "\n",
        "print(x_data)\n",
        "print(y_data)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data:\n",
            "1.0    1.0\n",
            "2.0    2.0\n",
            "3.0    3.0\n",
            "4.0    4.0\n",
            "5.0    5.0\n",
            "6.0    6.0\n",
            "Name: x, dtype: float64\n",
            "1.0     1.0\n",
            "2.0     4.0\n",
            "3.0     9.0\n",
            "4.0    16.0\n",
            "5.0    25.0\n",
            "6.0    36.0\n",
            "Name: y, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_aUTPvGRzwg"
      },
      "source": [
        "#Define gradient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTdfAF9fObrh"
      },
      "source": [
        "Derivative of **loss** with respect to $w$ is given by: \\\\\n",
        "\n",
        "`w.grad.data`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJlR3Z6tSlwX"
      },
      "source": [
        "# Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aDEl3yUSrU1",
        "outputId": "2871b8bd-7e78-4e6a-b2c8-75450504f045"
      },
      "source": [
        "learning_rate = 0.001\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(10): #n_epochs (aka iterations) are 10\n",
        "    for x_val, y_val in zip(x_data, y_data):\n",
        "        #compute loss for this step\n",
        "        l = nloss(x_val, y_val)\n",
        "        #backprop\n",
        "        l.backward() \n",
        "        # grad is automatically computed\n",
        "        print(\"\\tgrad: \", x_val, y_val, w.grad.data[0])\n",
        "        # alter w for this step \n",
        "        w.data = w.data - (learning_rate * w.grad.data)\n",
        "\n",
        "        # Manually zero the gradients after updating weights\n",
        "        w.grad.data.zero_()\n",
        "\n",
        "    print(\"progress:\", epoch, l.data[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tgrad:  1.0 1.0 tensor(0.)\n",
            "\tgrad:  2.0 4.0 tensor(44.3614)\n",
            "\tgrad:  3.0 9.0 tensor(944.4883)\n",
            "\tgrad:  4.0 16.0 tensor(11.2291)\n",
            "\tgrad:  5.0 25.0 tensor(-0.2548)\n",
            "\tgrad:  6.0 36.0 tensor(1.4670)\n",
            "progress: 0 tensor(0.0001)\n",
            "\tgrad:  1.0 1.0 tensor(0.)\n",
            "\tgrad:  2.0 4.0 tensor(-0.0198)\n",
            "\tgrad:  3.0 9.0 tensor(-0.2480)\n",
            "\tgrad:  4.0 16.0 tensor(-1.0045)\n",
            "\tgrad:  5.0 25.0 tensor(-0.0602)\n",
            "\tgrad:  6.0 36.0 tensor(0.3455)\n",
            "progress: 1 tensor(7.1712e-06)\n",
            "\tgrad:  1.0 1.0 tensor(0.)\n",
            "\tgrad:  2.0 4.0 tensor(-0.0047)\n",
            "\tgrad:  3.0 9.0 tensor(-0.0585)\n",
            "\tgrad:  4.0 16.0 tensor(-0.2368)\n",
            "\tgrad:  5.0 25.0 tensor(-0.0127)\n",
            "\tgrad:  6.0 36.0 tensor(0.0733)\n",
            "progress: 2 tensor(3.2307e-07)\n",
            "\tgrad:  1.0 1.0 tensor(0.)\n",
            "\tgrad:  2.0 4.0 tensor(-0.0010)\n",
            "\tgrad:  3.0 9.0 tensor(-0.0124)\n",
            "\tgrad:  4.0 16.0 tensor(-0.0503)\n",
            "\tgrad:  5.0 25.0 tensor(-0.0028)\n",
            "\tgrad:  6.0 36.0 tensor(0.0157)\n",
            "progress: 3 tensor(1.4901e-08)\n",
            "\tgrad:  1.0 1.0 tensor(0.)\n",
            "\tgrad:  2.0 4.0 tensor(-0.0002)\n",
            "\tgrad:  3.0 9.0 tensor(-0.0027)\n",
            "\tgrad:  4.0 16.0 tensor(-0.0108)\n",
            "\tgrad:  5.0 25.0 tensor(-0.0008)\n",
            "\tgrad:  6.0 36.0 tensor(0.0039)\n",
            "progress: 4 tensor(9.3132e-10)\n",
            "\tgrad:  1.0 1.0 tensor(0.)\n",
            "\tgrad:  2.0 4.0 tensor(-5.2883e-05)\n",
            "\tgrad:  3.0 9.0 tensor(-0.0007)\n",
            "\tgrad:  4.0 16.0 tensor(-0.0027)\n",
            "\tgrad:  5.0 25.0 tensor(0.)\n",
            "\tgrad:  6.0 36.0 tensor(0.)\n",
            "progress: 5 tensor(0.)\n",
            "\tgrad:  1.0 1.0 tensor(0.)\n",
            "\tgrad:  2.0 4.0 tensor(0.)\n",
            "\tgrad:  3.0 9.0 tensor(0.)\n",
            "\tgrad:  4.0 16.0 tensor(0.)\n",
            "\tgrad:  5.0 25.0 tensor(0.)\n",
            "\tgrad:  6.0 36.0 tensor(0.)\n",
            "progress: 6 tensor(0.)\n",
            "\tgrad:  1.0 1.0 tensor(0.)\n",
            "\tgrad:  2.0 4.0 tensor(0.)\n",
            "\tgrad:  3.0 9.0 tensor(0.)\n",
            "\tgrad:  4.0 16.0 tensor(0.)\n",
            "\tgrad:  5.0 25.0 tensor(0.)\n",
            "\tgrad:  6.0 36.0 tensor(0.)\n",
            "progress: 7 tensor(0.)\n",
            "\tgrad:  1.0 1.0 tensor(0.)\n",
            "\tgrad:  2.0 4.0 tensor(0.)\n",
            "\tgrad:  3.0 9.0 tensor(0.)\n",
            "\tgrad:  4.0 16.0 tensor(0.)\n",
            "\tgrad:  5.0 25.0 tensor(0.)\n",
            "\tgrad:  6.0 36.0 tensor(0.)\n",
            "progress: 8 tensor(0.)\n",
            "\tgrad:  1.0 1.0 tensor(0.)\n",
            "\tgrad:  2.0 4.0 tensor(0.)\n",
            "\tgrad:  3.0 9.0 tensor(0.)\n",
            "\tgrad:  4.0 16.0 tensor(0.)\n",
            "\tgrad:  5.0 25.0 tensor(0.)\n",
            "\tgrad:  6.0 36.0 tensor(0.)\n",
            "progress: 9 tensor(0.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnXW7hUWMaVH"
      },
      "source": [
        "#After learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4KHzkJxry-T",
        "outputId": "3e6ef313-1f7e-4826-f81a-a4ca6287c470"
      },
      "source": [
        "# After training\n",
        "print(\"predict (after training)\")\n",
        "print(\"input: 4\")\n",
        "print(\"model prediction (after training): \", nforward(10).data[0], \" -- correct answer: 100\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predict (after training)\n",
            "input: 4\n",
            "model prediction (after training):  tensor(100.)  -- correct answer: 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxVZaD6Klh2v"
      },
      "source": [
        "## Exercise II:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knPfe0vXlh2w"
      },
      "source": [
        "Use the above method for\n",
        "\n",
        "$y = 5x+3$\n",
        "\n",
        "**Hint:** You need to learn two values: $w$ and $b$. And your prediction\n",
        "function is\n",
        "\n",
        "$y_{pred} = w*x + b$\n",
        "\n",
        "and your gradient descent looks something like this:\n",
        "\n",
        "![img](https://media.giphy.com/media/O9rcZVmRcEGqI/giphy.gif \"alt text\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jA9EHCJ3A5Yr"
      },
      "source": [
        "# We know our model is linear\n",
        "# initialize the exponent. but we will learn this weight in the process below.\n",
        "w = Variable(torch.Tensor([3.0]),  requires_grad=True) \n",
        "b = Variable(torch.Tensor([3.0]),  requires_grad=True)\n",
        "# our model forward pass\n",
        "# this is actually our y_pred as we defined above\n",
        "def forward(x):\n",
        "   return x*w+b"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgvZESeECIPw"
      },
      "source": [
        "#Define the loss function of two parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGLpAnP7E-gL"
      },
      "source": [
        "import numpy as np\n",
        "# Loss function\n",
        "def loss(x, y):\n",
        "   y_pred = forward(x)\n",
        "   return (y_pred - y) * (y_pred - y)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMCMqnYOH8Fl"
      },
      "source": [
        "### Generate data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzIWVwpQCOvA",
        "outputId": "15aeea1f-513e-461a-f35e-d3011b7e1d33"
      },
      "source": [
        "from pylab import *\n",
        "import pandas as pd\n",
        "\n",
        "x = [1.0,2.0,3.0,4.0,5.0,6.0]\n",
        "y = [xx*5+3 for xx in x]\n",
        "\n",
        "data = {'x':x, 'y':y}\n",
        "df = pd.DataFrame(data=data, index=x)\n",
        "print(\"Training Data:\")\n",
        "x_data = df['x']\n",
        "y_data = df['y']\n",
        "\n",
        "print(x_data)\n",
        "print(y_data)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data:\n",
            "1.0    1.0\n",
            "2.0    2.0\n",
            "3.0    3.0\n",
            "4.0    4.0\n",
            "5.0    5.0\n",
            "6.0    6.0\n",
            "Name: x, dtype: float64\n",
            "1.0     8.0\n",
            "2.0    13.0\n",
            "3.0    18.0\n",
            "4.0    23.0\n",
            "5.0    28.0\n",
            "6.0    33.0\n",
            "Name: y, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3nBtJnjFUB_"
      },
      "source": [
        "#Define gradient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1--MWtMFXYG"
      },
      "source": [
        "Derivative of **loss** with respect to $w$ is given by: \\\\\n",
        "\n",
        "`w.grad.data`\n",
        "\n",
        "Derivative of **loss** with respect to $b$ is given by: \\\\\n",
        "\n",
        "`b.grad.data`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uN9Pe1vH2U8"
      },
      "source": [
        "#Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzOynm08INuu"
      },
      "source": [
        "learning_rate = 0.001\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(100): #n_epochs (aka iterations) are 10\n",
        "    for x_val, y_val in zip(x_data, y_data):\n",
        "        #compute loss for this step\n",
        "        l = loss(x_val, y_val)\n",
        "        #backprop\n",
        "        l.backward() \n",
        "        # alter w for this step \n",
        "        w.data = w.data - (learning_rate * w.grad.data)\n",
        "        b.data = b.data - (learning_rate * b.grad.data)\n",
        "        # Manually zero the gradients after updating weights\n",
        "        w.grad.data.zero_()\n",
        "        b.grad.data.zero_()\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-I0mHV1LMd6"
      },
      "source": [
        "#After learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbwELCKSLPRD",
        "outputId": "f59eee58-2bf7-4789-d23a-b328c3db0ba4"
      },
      "source": [
        "# After training\n",
        "print(\"predict (after training)\")\n",
        "print(\"input: 4\")\n",
        "print(\"model prediction (after training): \", forward(4).data[0], \" -- correct answer: 23\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predict (after training)\n",
            "input: 4\n",
            "model prediction (after training):  tensor(23.0315)  -- correct answer: 23\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}