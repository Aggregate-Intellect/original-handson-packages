# Quiz 2

#### Why do we use softmax instead of argmax as an activation function?


#### Why is secant not a commonly used activation function? Are there any cases where using secant as an activation function is preferable?


#### Is squared distance an acceptable loss function for binary classification? If no, why not?


#### If the K-L Divergence is zero, the two distributions being compared are
    * Identical
    * Completely different
    * INsufficient information provided


#### Why are we taking log probabilities instead of actual probabilities while calculating binary cross entropy loss function?


#### Input to a pytorch 1d convolution is (30, 16, 30) with kernel_size = 4, padding=2, stride=2, dilation=2. What would be the output shape?


#### Does Max Pooling help with reducing overfitting?
    * Heck Yeah!!!
    * Marginally, but there are better ways to reduce overfitting
    * No, it makes it worse
    * It has no relationship to overfitting whatsoever


#### What is the advantage, if any, of using reflection padding over zero padding?


#### For the MNIST dataset, max pooling is used rather than average pooling. Why is that?


#### In a CNN, it is preferable to have kernels with odd height and width values. Why is that?