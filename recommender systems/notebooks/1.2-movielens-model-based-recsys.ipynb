{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Based RecSys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jQYas5y7nls5"
   },
   "source": [
    "As before, the first thing is to load the data and get the most popular 50 movies, together with users that rated at least 6 of those movies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "whqa4ckAmIti"
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy.linalg import solve\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A3d88NDr6YqL"
   },
   "source": [
    "## Load MovieLens Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xgF3el8PDegU"
   },
   "outputs": [],
   "source": [
    "data_dir = \"../data/ml-20m\"\n",
    "ratings = pd.read_csv(f\"{data_dir}/ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XYFhNGYJV7qQ"
   },
   "outputs": [],
   "source": [
    "def get_records_for(ratings, n_most_popular_movies=50, user_min_seen_movies=5):\n",
    "    \"\"\"\n",
    "    ratings: pandas dataframe with raitngs\n",
    "    n_most_popular_movies: Number of desired most common movies to get info from.\n",
    "    user_min_seen_movies: Least number of movies that each user has rated.\n",
    "    returns: pandas dataframe containing only information for the top most_n movies\n",
    "    \"\"\"\n",
    "    # TO DO: Write your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x2jqnx1Q6YI5"
   },
   "source": [
    "Here is a sample solution for `get_records_for`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GDl69bvrV-Fr"
   },
   "outputs": [],
   "source": [
    "def get_records_for(ratings, n_most_popular_movies=50, user_min_seen_movies=5):\n",
    "    \"\"\"\n",
    "    ratings: pandas dataframe with raitngs\n",
    "    n_most_popular_movies: Number of desired most common movies to get info from.\n",
    "    user_min_seen_movies: Least number of movies that each user has rated.\n",
    "    returns: pandas dataframe containing only information for the top most_n movies\n",
    "    \"\"\"\n",
    "    \n",
    "    ratings = ratings.drop(\"timestamp\", axis=1)\n",
    "    \n",
    "    popular = ratings[['movieId', 'userId']].groupby('movieId', as_index=False)\\\n",
    "        .agg(len).sort_values('userId').tail(n_most_popular_movies)\n",
    "    \n",
    "    ratings = ratings[ratings['movieId'].isin(popular['movieId'].values)].copy(deep=True)\n",
    "    \n",
    "    lens = ratings.groupby(\"userId\", as_index=False).agg(len)\n",
    "    relevant_users = lens[lens['movieId'] >= user_min_seen_movies].userId\n",
    "    ratings = ratings[ratings['userId'].isin(relevant_users)]\n",
    "    \n",
    "    return ratings \n",
    "\n",
    "ratings = get_records_for(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MzHjHPEf6kZI"
   },
   "source": [
    "Note that the resulting information correspond to a user x item matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 347,
     "status": "ok",
     "timestamp": 1572409606458,
     "user": {
      "displayName": "Ella Chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDkHxBI3MfubseoYi1ejs9VfrRF0XXcAX0H7Y529g=s64",
      "userId": "06766956205880688168"
     },
     "user_tz": 240
    },
    "id": "jAwmYhWWV-he",
    "outputId": "e89f1e2d-1c02-43c6-c56d-fd474df53214"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 110676 unique users\n",
      "Only 0.38% of the possible ratings are known\n"
     ]
    }
   ],
   "source": [
    "unique = ratings.nunique()\n",
    "print(\"There are {} unique users\".format(unique[\"userId\"]))\n",
    "print(\"Only {:.2f}% of the possible ratings are known\".format(ratings.shape[0]/(unique[\"userId\"] * 50)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gvysiBYG6vSo"
   },
   "source": [
    "We should create some testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cuyD3lhWV-xC"
   },
   "outputs": [],
   "source": [
    "# Exercise: Make this faster?\n",
    "def create_matrix(df):\n",
    "\n",
    "    idx2user = df.userId.unique()\n",
    "    user2idx = {user:i for i, user in enumerate(idx2user)}\n",
    "    \n",
    "    idx2movie = df.movieId.unique()\n",
    "    movie2idx = {movie:i for i, movie in enumerate(idx2movie)}\n",
    "    \n",
    "    train = np.zeros((len(user2idx), len(movie2idx)))\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        \n",
    "        train[user2idx[row['userId']], movie2idx[row['movieId']]] = row['rating']\n",
    "    \n",
    "    test = np.zeros((len(user2idx), len(movie2idx)))\n",
    "    \n",
    "    for user_train, user_test in zip(train, test):\n",
    "        \n",
    "        nonzero = user_train.nonzero()[0]\n",
    "        \n",
    "        # Select 20% for testing\n",
    "        size = nonzero.shape[0]//5\n",
    "        test_ratings = np.random.choice(nonzero, size=size, replace=False)\n",
    "        \n",
    "        # Keep the records for testing\n",
    "        user_test[test_ratings] = user_train[test_ratings]\n",
    "        # Zero out for training\n",
    "        user_train[test_ratings] = 0\n",
    "        \n",
    "    return train, test, user2idx, movie2idx\n",
    "\n",
    "train, test, user2idx, movie2idx = create_matrix(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UKBlfBiQ7JOw"
   },
   "source": [
    "# Matrix Factorization\n",
    "\n",
    "The next step is to do matrix factorization. To do this we recall that the goal takes the form \n",
    "\n",
    "$$L_{exp} = \\sum\\limits_{u,i \\in S}(r_{ui} - \\textbf{x}_{u}^{\\intercal} \\cdot{} \\textbf{y}_{i})^{2} + \\lambda_{x} \\sum\\limits_{u} \\left\\Vert \\textbf{x}_{u} \\right\\Vert^{2} + \\lambda_{y} \\sum\\limits_{u} \\left\\Vert \\textbf{y}_{i} \\right\\Vert^{2}$$\n",
    "\n",
    "or more advanced,\n",
    "\n",
    "$$L_{WRMF} = \\sum\\limits_{u,i}c_{ui} \\big( p_{ui} - \\textbf{x}_{u}^{\\intercal} \\cdot{} \\textbf{y}_{i} \\big) ^{2} + \\lambda_{x} \\sum\\limits_{u} \\left\\Vert \\textbf{x}_{u} \\right\\Vert^{2} + \\lambda_{y} \\sum\\limits_{u} \\left\\Vert \\textbf{y}_{i} \\right\\Vert^{2}$$\n",
    "\n",
    "We only focussed on the first type and leave the second one as an exercise.\n",
    "\n",
    "We create a class that will take care of the model, a class should be able to do train and inference. Recall that the update rule is given by:\n",
    "\n",
    "$$ x_u = (M M^T + \\lambda_x \\mathbb{Id})^{-1} M R$$\n",
    "\n",
    "**Exercise**: Understand the difference between this and the Netflix paper update rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 51572,
     "status": "ok",
     "timestamp": 1572410874423,
     "user": {
      "displayName": "Ella Chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDkHxBI3MfubseoYi1ejs9VfrRF0XXcAX0H7Y529g=s64",
      "userId": "06766956205880688168"
     },
     "user_tz": 240
    },
    "id": "TY2J1IAzYcZD",
    "outputId": "f9010741-b5a7-4486-a07d-ba53aa1bbb5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 9, error: 1.0809, test_error: 2.9336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class MF:\n",
    "    \n",
    "    def __init__(self, user_x_item, rank, lambda_usr=0, lambda_item=0):\n",
    "        \n",
    "        self.data = user_x_item\n",
    "        self.nb_users, self.nb_items = self.data.shape\n",
    "        self.rank = rank\n",
    "        self.users = np.random.random((self.nb_users, self.rank))\n",
    "        self.items = np.random.random((self.nb_items, self.rank))\n",
    "        self.lambda_usr = lambda_usr\n",
    "        self.lambda_item = lambda_item\n",
    "    \n",
    "        \n",
    "    def train(self, nb_steps, test=None):\n",
    "        \n",
    "        for i in range(nb_steps):\n",
    "            \n",
    "            self.update_user()\n",
    "            self.update_item()\n",
    "            \n",
    "            if test is not None:\n",
    "                print(\"Step: {}, error: {:.4f}, test_error: {:.4f}\".\\\n",
    "                      format(i, self.error(), self.valid_error(test)), end=\"\\r\")\n",
    "            else:\n",
    "                print(\"Step: {}, error: {:.4f}\".format(i, self.error()), end=\"\\r\")\n",
    "\n",
    "        print(\"\\n\")\n",
    "            \n",
    "    def update_user(self):\n",
    "        \n",
    "        # Exercise: Complete this part\n",
    "        YTY = (self.items.T).dot(self.items)\n",
    "        reg = self.lambda_usr * np.eye(self.rank)\n",
    "        \n",
    "        for user_idx in range(self.nb_users):\n",
    "            self.users[user_idx, :] = \\\n",
    "                solve(YTY + reg, (self.data[user_idx, :].T).dot(self.items))\n",
    "        \n",
    "    \n",
    "    def update_item(self):\n",
    "        \n",
    "        # Exercise: Complete this part\n",
    "        XTX = (self.users.T).dot(self.users)\n",
    "        reg = self.lambda_item * np.eye(self.rank)\n",
    "        \n",
    "        for item_idx in range(self.nb_items):\n",
    "            self.items[item_idx, :] = \\\n",
    "                solve(XTX + reg, (self.data[:, item_idx].T).dot(self.users))\n",
    "    \n",
    "    def error(self):\n",
    "        \n",
    "        return np.sqrt((((self.data - np.matmul(self.users, self.items.T)) ** 2).mean()))\n",
    "    \n",
    "    def valid_error(self, test):\n",
    "        \n",
    "        preds = np.matmul(self.users, self.items.T)\n",
    "        \n",
    "        error = 0\n",
    "        counter = 0\n",
    "        \n",
    "        for user, pred in zip(test, preds):\n",
    "            \n",
    "            nonzero = user.nonzero()[0]\n",
    "            counter += nonzero.shape[0]\n",
    "            error += ((user[nonzero] - pred[nonzero])**2).sum()\n",
    "        \n",
    "        return np.sqrt(error/counter)\n",
    "            \n",
    "    \n",
    "    \n",
    "mf = MF(train, 20, 0.4, 0.4)\n",
    "mf.train(10, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "llhdPOuI75v1"
   },
   "source": [
    "We can see convergence occurs rapidly. \n",
    "\n",
    "# A back propagation approach\n",
    "\n",
    "The question that we have is a minimization question, so we could use back-propagation technique to solve it, we do this next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f95DZPbiYgvW"
   },
   "outputs": [],
   "source": [
    "class MFD(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_users, n_items, rank):\n",
    "        \n",
    "        super(MFD, self).__init__()\n",
    "        \n",
    "        self.users = nn.Embedding(n_users, rank)\n",
    "        self.items = nn.Embedding(n_items, rank)\n",
    "        self.rank = rank\n",
    "    \n",
    "    \n",
    "    def forward(self, users, items):\n",
    "        \n",
    "        users = self.users(users)\n",
    "        items = self.items(items)\n",
    "        \n",
    "        users = users.unsqueeze(1)\n",
    "        items = items.unsqueeze(2)\n",
    "\n",
    "        ranks = torch.bmm(users, items)\n",
    "        \n",
    "        return ranks.squeeze()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T7hCQBWo8SuU"
   },
   "source": [
    "And we create the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 414525,
     "status": "ok",
     "timestamp": 1572410472901,
     "user": {
      "displayName": "Ella Chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDkHxBI3MfubseoYi1ejs9VfrRF0XXcAX0H7Y529g=s64",
      "userId": "06766956205880688168"
     },
     "user_tz": 240
    },
    "id": "GnTEVWfw8QhI",
    "outputId": "c71f4c9c-1c39-40f1-8272-23b639fe890a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 valid_loss 4.636169910430908\n",
      "Epoch 2/10 valid_loss 4.132117748260498\n",
      "Epoch 3/10 valid_loss 4.0301432609558105\n",
      "Epoch 4/10 valid_loss 4.010544300079346\n",
      "Epoch 5/10 valid_loss 4.006823539733887\n",
      "Epoch 6/10 valid_loss 4.006123065948486\n",
      "Epoch 7/10 valid_loss 4.005992889404297\n",
      "Epoch 8/10 valid_loss 4.005970001220703\n",
      "Epoch 9/10 valid_loss 4.0059661865234375\n",
      "Epoch 10/10 valid_loss 4.005965709686279\n"
     ]
    }
   ],
   "source": [
    "def train(epochs, ratings, user2idx, movie2idx):\n",
    "    \n",
    "    nb_users = ratings.userId.nunique()\n",
    "    nb_items = ratings.movieId.nunique()\n",
    "    train_ratings, test_ratings = train_test_split(ratings, test_size=0.2)\n",
    "    \n",
    "    users = torch.tensor([user2idx[u] for u in train_ratings.userId]).long()\n",
    "    movies = torch.tensor([movie2idx[m] for m in train_ratings.movieId]).long()\n",
    "    ratings = torch.tensor(train_ratings.rating.values).float()\n",
    "    \n",
    "    data = TensorDataset(users, movies, ratings)\n",
    "    dataloader = DataLoader(data, batch_size=4096, shuffle=True)\n",
    "    \n",
    "    users_valid = torch.tensor([user2idx[u] for u in test_ratings.userId]).long()\n",
    "    movies_valid = torch.tensor([movie2idx[m] for m in test_ratings.movieId]).long()\n",
    "    ratings_valid = torch.tensor(test_ratings.rating.values).float()\n",
    "      \n",
    "    model = MFD(nb_users, nb_items, 30)\n",
    "    \n",
    "    optim = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=1)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        for users, items, ratings in dataloader:\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            pred_rat = model(users, items)\n",
    "            loss = ((pred_rat - ratings)**2).mean()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            print(\"Epoch {}/{} loss {}\".format(i+1, epochs, torch.sqrt(loss)), end=\"\\r\")\n",
    "        \n",
    "        model.eval()\n",
    "        pred_rat = model(users_valid, movies_valid)\n",
    "        loss = ((pred_rat - ratings_valid)**2).mean()   \n",
    "        print(\"Epoch {}/{} valid_loss {}\".format(i+1, epochs, torch.sqrt(loss)))\n",
    "        model.train()\n",
    "        \n",
    "train(10, ratings, user2idx, movie2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 611,
     "status": "ok",
     "timestamp": 1572410473514,
     "user": {
      "displayName": "Ella Chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDkHxBI3MfubseoYi1ejs9VfrRF0XXcAX0H7Y529g=s64",
      "userId": "06766956205880688168"
     },
     "user_tz": 240
    },
    "id": "IB6V5oLf8WZP",
    "outputId": "4870240f-2859-4667-93e8-4895f74efa88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(torch.rand(100,1, 3), torch.rand(100, 3, 1)).squeeze().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_gOErmru8bv5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Session_1.2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
