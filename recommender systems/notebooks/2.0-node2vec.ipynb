{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IS3VyEkcUW8N"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "SEED = 1\n",
    "torch.random.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LEukdBMLUW8I"
   },
   "source": [
    "# Atomic Experiments\n",
    "\n",
    "## Node2Vec\n",
    "\n",
    "In order to gain better insight on Node2Vec let's design an atomic experiment. \n",
    "\n",
    "Suppose that we have the following graph\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../figures/graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FoCQ1yoMWpf-"
   },
   "source": [
    "and we would like to create the Node2Vec embedding. Try answering the following questions before running the code:\n",
    "\n",
    "1. What is a good choice for the embedding dimension?\n",
    "2. What do you expect to find in the vector representations?\n",
    "3. How long do you expect this to take training? why?\n",
    "4. What is a good window size?\n",
    "5. How do you think the weights A, B, C, and D affect the results?\n",
    "\n",
    "### A math question:\n",
    "\n",
    "- How to transform weights into probabilities?\n",
    "\n",
    "# Creating the embeddings\n",
    "\n",
    "We need to do several things:\n",
    "\n",
    "0. Imports, seeds\n",
    "1. Create a way of representing the graph and the weights.\n",
    "2. Create the random walks.\n",
    "3. Use the word2vec embeddings. \n",
    "\n",
    "# 0. Preparations\n",
    "\n",
    "We import the needed packages and set the random seeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UHQa6gkUUW8T"
   },
   "source": [
    "## 1. Encoding the Graph\n",
    "\n",
    "There are many ways of encoding a graph. We will use a simple way where we keep a dictionary of current nodes to the nodes that it reaches and their corresponding weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YPuuum1nUW8U"
   },
   "outputs": [],
   "source": [
    "def create_graph(A: int=1, B: int=2, C: int=3, D: int=4) -> dict:\n",
    "    '''\n",
    "    Function that generates graph of figure above based on weights. Graph captured as a dictionary \n",
    "    In the graph shown above:\n",
    "    Yellow = Y\n",
    "    Blue = B\n",
    "    Green = G\n",
    "    Red = R\n",
    "    Soft Yellow = SY\n",
    "    Soft Blue = SB\n",
    "    Soft Green = SG\n",
    "    '''\n",
    "    \n",
    "    graph = {}\n",
    "    graph[\"G\"] = {\"B\": A, \"Y\": C}\n",
    "    graph[\"B\"] = {\"G\": A, \"Y\": B}\n",
    "    graph[\"Y\"] = {\"B\": B, \"G\": C, \"R\":D}\n",
    "    \n",
    "    graph[\"R\"] = {\"Y\": D, \"SY\": D}\n",
    "    \n",
    "    graph[\"SG\"] = {\"SB\": A, \"SY\": C}\n",
    "    graph[\"SB\"] = {\"SG\": A, \"SY\": B}\n",
    "    graph[\"SY\"] = {\"SB\": B, \"SG\": C, \"R\":D}\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mavRuNivUW8Y"
   },
   "outputs": [],
   "source": [
    "graph = create_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x3IM8XY4UW8b"
   },
   "source": [
    "## 2. Creating the random walks\n",
    "\n",
    "We need to create a large collection of walks. We will leave the number of steps and the number of samples as parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mx2iLtxrUW8d"
   },
   "outputs": [],
   "source": [
    "# Returns what node to go next\n",
    "def next_node(graph: dict, node: str) -> str:\n",
    "    \"\"\"\n",
    "    Function that takes a graph in the form of a dictionary and a node and returns what node to go next\n",
    "    args:\n",
    "        graph : dictionary capturing:\n",
    "            keys - nodes \n",
    "            values - dictionary of next node to move to and corresponding weight\n",
    "        node : string capturing current node where the walker is located\n",
    "    returns: string captring what node to go next from current node\n",
    "    \"\"\"\n",
    "    \n",
    "    # ===== Write your code here (HARD) ========\n",
    "    neighbors = graph[node]\n",
    "    \n",
    "    n = []\n",
    "    dist = []\n",
    "    total = 0\n",
    "    for key, val in neighbors.items():\n",
    "        n.append(key)\n",
    "        dist.append(val)\n",
    "        total += val\n",
    "    \n",
    "    dist = [p/total for p in dist]\n",
    "    # =========================================== \n",
    "    \n",
    "    return np.random.choice(n,1,p=dist)[0]\n",
    "    \n",
    "\n",
    "def walk_from_node(graph: dict, node: str, steps: int=5) -> list:\n",
    "    \"\"\"\n",
    "    Function that returns a random walk as a list based on a starting node and the whole graph given as a dictionary\n",
    "    args:\n",
    "        graph : dictionary capturing:\n",
    "            keys - nodes \n",
    "            values - dictionary of next node to move to and corresponding weight\n",
    "        node : string capturing current node where the walker is located\n",
    "        steps : integer representing number of steps the walker will take before it stops at the end node\n",
    "    returns: walk - random walk in the form of a list\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    walk = []\n",
    "    \n",
    "    # =========== Write your code here ===========\n",
    "    for step in range(steps):\n",
    "        walk.append(node)\n",
    "        node = next_node(graph, node)\n",
    "    # ===========================================    \n",
    "    \n",
    "    return walk\n",
    "\n",
    "\n",
    "def create_random_walks(graph: dict, walker_steps: int=5, num_walkers: int=3) -> list:\n",
    "    \"\"\"\n",
    "    Function that generates a list of random walks. Each random walk in the list is a list in itself\n",
    "    args:\n",
    "        graph : dictionary capturing:\n",
    "            keys - nodes \n",
    "            values - dictionary of next node to move to and corresponding weight\n",
    "        walker_steps : integer representing number of steps each walker in the list of walkes will take before it stops\n",
    "                    this is also the length of each walker in the list of walkers\n",
    "        num_walkers : integer representing the number of walkers to be generated\n",
    "        \n",
    "    returns: walks_list - list of random walkers\n",
    "    \"\"\"\n",
    "    \n",
    "    walks_list = []\n",
    "    \n",
    "    # =========== Write your code here ===========\n",
    "    for _ in range(num_walkers):\n",
    "        for node in [\"G\", \"B\", \"Y\", \"R\", \"SG\", \"SB\", \"SY\"]:\n",
    "            walks_list.append(walk_from_node(graph, node, walker_steps))\n",
    "    # ===========================================        \n",
    "    \n",
    "    return walks_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xjLjAjBqUW8h"
   },
   "source": [
    "We can get some example with the next line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 666,
     "status": "ok",
     "timestamp": 1573691394321,
     "user": {
      "displayName": "Felipe Perez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAlzl1P5N6zcpeIpQs5IsiUkcxTSQSPDhTtpHRG=s64",
      "userId": "00425449054874410322"
     },
     "user_tz": 300
    },
    "id": "BSF5SS8ZUW8j",
    "outputId": "225b67e2-5a11-4e91-8f52-d48fdf852722"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['G', 'Y', 'R', 'Y', 'G', 'B', 'G', 'B', 'Y', 'G'],\n",
       " ['B', 'Y', 'R', 'Y', 'R', 'Y', 'R', 'Y', 'R', 'Y'],\n",
       " ['Y', 'R', 'SY', 'SG', 'SY', 'R', 'SY', 'SB', 'SG', 'SB'],\n",
       " ['R', 'Y', 'G', 'Y', 'G', 'Y', 'G', 'Y', 'R', 'Y'],\n",
       " ['SG', 'SY', 'R', 'Y', 'R', 'Y', 'G', 'Y', 'G', 'Y'],\n",
       " ['SB', 'SG', 'SY', 'SB', 'SG', 'SY', 'SB', 'SY', 'SB', 'SY'],\n",
       " ['SY', 'SB', 'SY', 'R', 'Y', 'B', 'Y', 'R', 'SY', 'R'],\n",
       " ['G', 'Y', 'B', 'G', 'Y', 'G', 'B', 'Y', 'G', 'Y'],\n",
       " ['B', 'Y', 'R', 'SY', 'SG', 'SY', 'R', 'Y', 'R', 'SY'],\n",
       " ['Y', 'B', 'Y', 'G', 'Y', 'G', 'B', 'Y', 'R', 'Y']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = create_random_walks(graph, 10, 100)\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OEnQSJkBUW8n"
   },
   "source": [
    "## 3. Creating the Embedings\n",
    "Now that we have the \"sentences\" we need to transform them into numerical labels that represent the one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m6GNETU6UW8o"
   },
   "outputs": [],
   "source": [
    "node2idx = {\"G\": 0, \"B\": 1, \"Y\":2, \"R\":3, \"SG\":4, \"SB\":5, \"SY\":6}\n",
    "# geneate idx2node programmatically \n",
    "idx2node = dict((v,k) for k,v in node2idx.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'G': 0, 'B': 1, 'Y': 2, 'R': 3, 'SG': 4, 'SB': 5, 'SY': 6}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'G', 1: 'B', 2: 'Y', 3: 'R', 4: 'SG', 5: 'SB', 6: 'SY'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2pa9Pqf3UW8r"
   },
   "source": [
    "Next we create the skip-gram model. First the pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XTRui-bhUW8r"
   },
   "outputs": [],
   "source": [
    "def create_pairs(sentence: list, window: int) -> list:\n",
    "    \"\"\"\n",
    "    Function that returns a list of pairs. Each pair is a list in itself represents the indices resulting from\n",
    "    the skip-gram approach for word2vec\n",
    "    args:\n",
    "         sentence: list capturing the \"sentences\" generated by the random walkers\n",
    "         window: integer used in the skip-gram method - it is the maximum context location at which the words\n",
    "                  need to be predicted\n",
    "    returns: list of pairs the indices resulting from the skip-gram approach for word2vec\n",
    "    \"\"\"\n",
    "    \n",
    "    assert window>0, \"The window size should be greater than 0\"\n",
    "    pairs_list = []\n",
    "    \n",
    "    # =========== Write your code here ===========\n",
    "    l = len(sentence)\n",
    "    for i in range(l):\n",
    "        for j in range(max(i-window,0), min(i+window+1, l)):\n",
    "            if i!=j:\n",
    "                pairs_list.append([sentence[i], sentence[j]])\n",
    "    # ===========================================     \n",
    "    \n",
    "    return pairs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TBuhnpLYUW8u"
   },
   "source": [
    "We can use this to generate our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2N8HchLbUW8v"
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for sentence in sentences:\n",
    "    pair_ = create_pairs([node2idx[node] for node in sentence], 1)\n",
    "    data += pair_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 368,
     "status": "ok",
     "timestamp": 1573691628656,
     "user": {
      "displayName": "Felipe Perez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAlzl1P5N6zcpeIpQs5IsiUkcxTSQSPDhTtpHRG=s64",
      "userId": "00425449054874410322"
     },
     "user_tz": 300
    },
    "id": "gz6MsDviVHyS",
    "outputId": "de7d4abc-55ab-4a61-cf18-7e9e8fb1a53b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 2], [2, 0], [2, 3], [3, 2], [3, 2]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kBKslBbFUW8x"
   },
   "source": [
    "and then create our embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f2DJz6_UUW8y"
   },
   "outputs": [],
   "source": [
    "emb_center = torch.nn.Embedding(7,3)\n",
    "emb_context = torch.nn.Embedding(7,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6iXZvV1vUW81"
   },
   "source": [
    "We do the training in a particular way to introduce the concept of schedule learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21341,
     "status": "ok",
     "timestamp": 1573692058491,
     "user": {
      "displayName": "Felipe Perez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAlzl1P5N6zcpeIpQs5IsiUkcxTSQSPDhTtpHRG=s64",
      "userId": "00425449054874410322"
     },
     "user_tz": 300
    },
    "id": "haK6ZFD8UW82",
    "outputId": "a915e750-8bff-448c-f262-398fe8897d0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Learning rate of  0.1\n",
      "Using Learning rate of  0.01\n",
      "Using Learning rate of  0.001\n",
      "Using Learning rate of  1e-05\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "learning_rates = {'schedule_1': 0.1, 'schedule_2': 0.01, 'schedule_3': 0.001, 'schedule_4': 0.00001}\n",
    "\n",
    "print(\"Using Learning rate of \", learning_rates['schedule_1'])\n",
    "for pair in data:\n",
    "    a, b = pair\n",
    "    emb_center.zero_grad()\n",
    "    emb_context.zero_grad()\n",
    "    a_against_all = torch.matmul(\n",
    "        emb_context(torch.tensor([0, 1, 2, 3, 4, 5, 6])),\n",
    "        emb_center(torch.tensor([a])).transpose(0,1))\n",
    "    result = torch.nn.functional.log_softmax(a_against_all, dim=0)\n",
    "    loss = torch.nn.functional.nll_loss(\n",
    "        result.view(1, -1), torch.tensor([b]))\n",
    "    loss.backward()\n",
    "\n",
    "    losses.append(loss.item())\n",
    "    for param in emb_center.parameters():\n",
    "         param.data -= learning_rates['schedule_1']*param.grad\n",
    "    for param in emb_context.parameters():\n",
    "         param.data -= learning_rates['schedule_1']*param.grad\n",
    "\n",
    "print(\"Using Learning rate of \", learning_rates['schedule_2'])\n",
    "for pair in data:\n",
    "    a, b = pair\n",
    "    emb_center.zero_grad()\n",
    "    emb_context.zero_grad()\n",
    "    a_against_all = torch.matmul(\n",
    "        emb_context(torch.tensor([0, 1, 2, 3, 4, 5, 6])),\n",
    "        emb_center(torch.tensor([a])).transpose(0,1))\n",
    "    result = torch.nn.functional.log_softmax(a_against_all, dim=0)\n",
    "    loss = torch.nn.functional.nll_loss(\n",
    "        result.view(1, -1), torch.tensor([b]))\n",
    "    loss.backward()\n",
    "\n",
    "    losses.append(loss.item())\n",
    "    for param in emb_center.parameters():\n",
    "         param.data -= learning_rates['schedule_2']*param.grad\n",
    "    for param in emb_context.parameters():\n",
    "         param.data -= learning_rates['schedule_2']*param.grad\n",
    "\n",
    "            \n",
    "print(\"Using Learning rate of \", learning_rates['schedule_3'])\n",
    "for pair in data:\n",
    "    a, b = pair\n",
    "    emb_center.zero_grad()\n",
    "    emb_context.zero_grad()\n",
    "    a_against_all = torch.matmul(\n",
    "        emb_context(torch.tensor([0, 1, 2, 3, 4, 5, 6])),\n",
    "        emb_center(torch.tensor([a])).transpose(0,1))\n",
    "    result = torch.nn.functional.log_softmax(a_against_all, dim=0)\n",
    "    loss = torch.nn.functional.nll_loss(\n",
    "        result.view(1, -1), torch.tensor([b]))\n",
    "    loss.backward()\n",
    "\n",
    "    losses.append(loss.item())\n",
    "    for param in emb_center.parameters():\n",
    "         param.data -= learning_rates['schedule_3']*param.grad\n",
    "    for param in emb_context.parameters():\n",
    "         param.data -= learning_rates['schedule_3']*param.grad\n",
    "\n",
    "print(\"Using Learning rate of \", learning_rates['schedule_4'])\n",
    "for pair in data:\n",
    "    a, b = pair\n",
    "    emb_center.zero_grad()\n",
    "    emb_context.zero_grad()\n",
    "    a_against_all = torch.matmul(\n",
    "        emb_context(torch.tensor([0, 1, 2, 3, 4, 5, 6])),\n",
    "        emb_center(torch.tensor([a])).transpose(0,1))\n",
    "    result = torch.nn.functional.log_softmax(a_against_all, dim=0)\n",
    "    loss = torch.nn.functional.nll_loss(\n",
    "        result.view(1, -1), torch.tensor([b]))\n",
    "    loss.backward()\n",
    "\n",
    "    # print(a,b,\"\\n\",result, result[b])\n",
    "    losses.append(loss.item())\n",
    "    for param in emb_center.parameters():\n",
    "         param.data -= learning_rates['schedule_4']*param.grad\n",
    "    for param in emb_context.parameters():\n",
    "         param.data -= learning_rates['schedule_4']*param.grad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3MkkOR00UW84"
   },
   "source": [
    "Let's take a look at the losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1704,
     "status": "ok",
     "timestamp": 1573308960285,
     "user": {
      "displayName": "Felipe Perez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAlzl1P5N6zcpeIpQs5IsiUkcxTSQSPDhTtpHRG=s64",
      "userId": "00425449054874410322"
     },
     "user_tz": 300
    },
    "id": "6N6B7JZXUW85",
    "outputId": "6fc96b08-e91a-4554-b72f-fc48ca12414b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Note: this code is not working properly\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iBtjLonsUW88"
   },
   "source": [
    "and the resulting probability distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 346,
     "status": "ok",
     "timestamp": 1573692456497,
     "user": {
      "displayName": "Felipe Perez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAlzl1P5N6zcpeIpQs5IsiUkcxTSQSPDhTtpHRG=s64",
      "userId": "00425449054874410322"
     },
     "user_tz": 300
    },
    "id": "iQt0iBTOUW89",
    "outputId": "62b79620-9148-4f5d-c158-35b6e28db033"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0050, 0.3160, 0.3240, 0.0010, 0.0000, 0.0010, 0.0020],\n",
       "        [0.2640, 0.0060, 0.2530, 0.0010, 0.0000, 0.0000, 0.0010],\n",
       "        [0.7280, 0.6740, 0.0010, 0.5210, 0.0030, 0.0030, 0.0000],\n",
       "        [0.0000, 0.0000, 0.4190, 0.0000, 0.0000, 0.0000, 0.4200],\n",
       "        [0.0000, 0.0010, 0.0020, 0.0010, 0.0060, 0.3500, 0.3260],\n",
       "        [0.0000, 0.0000, 0.0010, 0.0010, 0.2920, 0.0060, 0.2490],\n",
       "        [0.0020, 0.0030, 0.0000, 0.4760, 0.6990, 0.6390, 0.0020]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_dist = torch.nn.functional.softmax(\n",
    "    torch.matmul( emb_context(torch.tensor([0,1,2,3,4,5,6])),\n",
    "                 emb_center(torch.tensor([0,1,2,3,4,5,6])).transpose(0,1)),\n",
    "    dim = 0)\n",
    "(1000*prob_dist).round()/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "02VU_ij_UW9A"
   },
   "source": [
    "and in order to run some experiments let's get the individual vector representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1573692464820,
     "user": {
      "displayName": "Felipe Perez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAlzl1P5N6zcpeIpQs5IsiUkcxTSQSPDhTtpHRG=s64",
      "userId": "00425449054874410322"
     },
     "user_tz": 300
    },
    "id": "kezru53MUW9B",
    "outputId": "fbd96d00-2c2b-45ea-db47-83890bda96ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.9218,  1.6399,  0.3617],\n",
       "        [-0.7324, -0.4179,  2.4045],\n",
       "        [-1.5934, -1.3765, -0.4126],\n",
       "        [ 0.4154,  1.6028,  1.3406],\n",
       "        [ 1.2257,  1.9169, -1.0491],\n",
       "        [ 2.2683, -0.1371,  1.0720],\n",
       "        [ 0.9944, -1.1212, -1.5599]], requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[G, B, Y, R, SG, SB, SY] = emb_center.weight\n",
    "emb_center.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i-SE5NsHUW9E"
   },
   "source": [
    "## Analogies\n",
    "\n",
    "It is clear from the graph that there are cluster that are similar, we could think of them as analogies. We need something else first. \n",
    "\n",
    "### Finding the closest one\n",
    "\n",
    "We need to a function to find the closest point (in cosine distance) to a given one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7eAZM4SPUW9F"
   },
   "outputs": [],
   "source": [
    "def cosine_distance(a: torch.Tensor, b: torch.Tensor) -> float:\n",
    "    \"\"\"\n",
    "    Function that computes the cosine distance between two tensors\n",
    "    args: a, b - tensors\n",
    "    returns: cosine distance \n",
    "    \"\"\"\n",
    "    \n",
    "    # =========== Write your code here ===========\n",
    "    d = 1-torch.mul(a,b).sum()/torch.sqrt(torch.mul(a,a).sum() * torch.mul(b,b).sum())\n",
    "    # ============================================\n",
    "    \n",
    "    return d\n",
    "\n",
    "def closest(a: torch.Tensor) -> tuple:\n",
    "    \"\"\"\n",
    "    Function that, based on a node embeding, returns tuple capuring the string with the closest node and distance to\n",
    "    closest node\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    min_distance = float(\"inf\")\n",
    "    mini_at = None \n",
    "    \n",
    "    # =========== Write your code here ===========\n",
    "    for node, label in node2idx.items():\n",
    "        if cosine_distance(a, emb_center.weight[label]) < min_distance:\n",
    "            min_distance = cosine_distance(a, emb_center.weight[label])\n",
    "            mini_at = node\n",
    "    # ============================================\n",
    "    \n",
    "    return mini_at, min_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1rDdX_QtUW9I"
   },
   "source": [
    "we can check that this is well defined if the following returns (Y,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 442,
     "status": "ok",
     "timestamp": 1573692484098,
     "user": {
      "displayName": "Felipe Perez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAlzl1P5N6zcpeIpQs5IsiUkcxTSQSPDhTtpHRG=s64",
      "userId": "00425449054874410322"
     },
     "user_tz": 300
    },
    "id": "vfkwS5-fUW9I",
    "outputId": "9437ad0a-1404-44af-f916-ee3853661569"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Y', tensor(0., grad_fn=<RsubBackward1>))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9aTpu5LuUW9L"
   },
   "source": [
    "### Some analogies\n",
    "\n",
    "Let's see if we can get some analogies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 348,
     "status": "ok",
     "timestamp": 1573692499377,
     "user": {
      "displayName": "Felipe Perez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAlzl1P5N6zcpeIpQs5IsiUkcxTSQSPDhTtpHRG=s64",
      "userId": "00425449054874410322"
     },
     "user_tz": 300
    },
    "id": "N1mww1uuUW9M",
    "outputId": "b45f7746-8c0b-4106-c286-42be54ef8b71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('SG', tensor(0.0015, grad_fn=<RsubBackward1>))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest(SB-B+G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 572,
     "status": "ok",
     "timestamp": 1573692508549,
     "user": {
      "displayName": "Felipe Perez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAlzl1P5N6zcpeIpQs5IsiUkcxTSQSPDhTtpHRG=s64",
      "userId": "00425449054874410322"
     },
     "user_tz": 300
    },
    "id": "Myz9GQQ8UW9T",
    "outputId": "07a4918c-0c80-4af4-e2bb-e5dc852779d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('SB', tensor(0.0013, grad_fn=<RsubBackward1>))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest(SG-G+B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1573692518886,
     "user": {
      "displayName": "Felipe Perez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAlzl1P5N6zcpeIpQs5IsiUkcxTSQSPDhTtpHRG=s64",
      "userId": "00425449054874410322"
     },
     "user_tz": 300
    },
    "id": "HrNn0ACqUW9a",
    "outputId": "7c50fcab-c135-4b03-cf66-b94aa7acd49d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('SG', tensor(0.0242, grad_fn=<RsubBackward1>))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest(SY-Y+G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WIbMOIvHUW9d"
   },
   "source": [
    "# Some Remarks/Questions\n",
    "\n",
    "## From counts to probability distributions\n",
    "\n",
    "We can get the expected results by a simple count as we did in our previous experiment. Make sure that you understand how the following relates to the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 594,
     "status": "ok",
     "timestamp": 1573273457383,
     "user": {
      "displayName": "Felipe Perez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAlzl1P5N6zcpeIpQs5IsiUkcxTSQSPDhTtpHRG=s64",
      "userId": "00425449054874410322"
     },
     "user_tz": 300
    },
    "id": "G4MSin56UW9e",
    "outputId": "dca2a342-0c03-4d5e-f37e-2e0b40f1d58e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {(0, 2): 959,\n",
       "             (2, 0): 959,\n",
       "             (2, 3): 1243,\n",
       "             (3, 2): 1243,\n",
       "             (0, 1): 353,\n",
       "             (1, 0): 353,\n",
       "             (1, 2): 686,\n",
       "             (2, 1): 686,\n",
       "             (3, 6): 1194,\n",
       "             (6, 3): 1194,\n",
       "             (6, 4): 892,\n",
       "             (4, 6): 892,\n",
       "             (6, 5): 628,\n",
       "             (5, 6): 628,\n",
       "             (5, 4): 345,\n",
       "             (4, 5): 345})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = defaultdict(int)\n",
    "for d in data:\n",
    "    counts[tuple(d)]+=1\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PhKlVXNcUW9g"
   },
   "source": [
    "## Embedding dimension \n",
    "\n",
    "The embedding dimension here is a tricky business. Try to use dim = 2 and see what happens? Can you get the analogy results? (Hard) Why do you think that happens? \n",
    "\n",
    "## Different seeds\n",
    "\n",
    "What happens if we change the random seed to 13, or 42. Do we get the same results? what conclusions can you gather about this?\n",
    "\n",
    "## Loss function\n",
    "\n",
    "Look at the loss function. Make sure that you understand why the LR change creates a decrease in the loss. Can you ever get a loss of zero? why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Node to Vector.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
