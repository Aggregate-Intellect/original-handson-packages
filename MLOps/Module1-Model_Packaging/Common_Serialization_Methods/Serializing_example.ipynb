{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Serializing_example_pf.ipynb","provenance":[{"file_id":"1miA_jYoFBd3LPT6_mq9ItFOTSRgFFWKS","timestamp":1622996529677}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"erBt9Rf4IPcQ"},"source":["# **Serializing Example**"]},{"cell_type":"markdown","metadata":{"id":"vxfaY0fv88U7"},"source":["# Agenda:\n","The main Agenda of this notebook is to demostrate the two different mehtods of serialization. \n","1. model.save() method (inbuild method of pytorch)\n","2. model.state_dict() method.\n","\n","we are also going to show the comparison of both of them, and clarify why the pickle is recommendaed with comparsion to model.save().\n","\n","Please, load the second notebook (*link) into another tab for hand on practice. [Note: If colab do not allow the second session, then change the runtime for second notebook from gpu to tpu.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"rlCnxoGB9KoO"},"source":["# Model Serialization Example\n","\n","This is a simple model used for illustrating the fragile nature of serializing object with Python's Pickle format."]},{"cell_type":"code","metadata":{"id":"LsXt1MZV9QRx"},"source":["# import dependencies\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.nn import functional as F\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","from torchsummary import summary\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UfRBsUug-fpu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622994678890,"user_tz":240,"elapsed":682,"user":{"displayName":"vedant dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKleU9y9wWyYjI0z0kjFpSMh-CBCSZOHmSja1_Pw=s64","userId":"04728257226452809178"}},"outputId":"d9f33003-dca1-4a6b-a780-71446ba51a7e"},"source":["# Download the csv to the content directory in colab\n","\n","! wget https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-06-06 15:51:18--  https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\n","Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3975 (3.9K) [text/plain]\n","Saving to: ‘iris.csv.3’\n","\n","\riris.csv.3            0%[                    ]       0  --.-KB/s               \riris.csv.3          100%[===================>]   3.88K  --.-KB/s    in 0s      \n","\n","2021-06-06 15:51:18 (24.5 MB/s) - ‘iris.csv.3’ saved [3975/3975]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rQ_prRPT_v2u"},"source":["# Data Preparation\n","\n"]},{"cell_type":"code","metadata":{"id":"S5qQl3ubAV2G","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1622994678892,"user_tz":240,"elapsed":39,"user":{"displayName":"vedant dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKleU9y9wWyYjI0z0kjFpSMh-CBCSZOHmSja1_Pw=s64","userId":"04728257226452809178"}},"outputId":"a17f2154-f87f-4253-f647-475ba2f59c7e"},"source":["iris_df = pd.read_csv('/content/iris.csv')\n","iris_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sepal.length</th>\n","      <th>sepal.width</th>\n","      <th>petal.length</th>\n","      <th>petal.width</th>\n","      <th>variety</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.1</td>\n","      <td>3.5</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>Setosa</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.9</td>\n","      <td>3.0</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>Setosa</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.7</td>\n","      <td>3.2</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","      <td>Setosa</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.6</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>Setosa</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.0</td>\n","      <td>3.6</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>Setosa</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   sepal.length  sepal.width  petal.length  petal.width variety\n","0           5.1          3.5           1.4          0.2  Setosa\n","1           4.9          3.0           1.4          0.2  Setosa\n","2           4.7          3.2           1.3          0.2  Setosa\n","3           4.6          3.1           1.5          0.2  Setosa\n","4           5.0          3.6           1.4          0.2  Setosa"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"4znwwejN_F1h","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1622994678895,"user_tz":240,"elapsed":37,"user":{"displayName":"vedant dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKleU9y9wWyYjI0z0kjFpSMh-CBCSZOHmSja1_Pw=s64","userId":"04728257226452809178"}},"outputId":"0c41de9d-2f8d-43e8-cb9f-4c164eb710e0"},"source":["# Converting label data to integer for traiing the model.\n","\n","species = {'Setosa': 0,'Versicolor': 1, 'Virginica': 2}\n","iris_df['variety'] = [species[item] for item in iris_df['variety']] \n","iris_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sepal.length</th>\n","      <th>sepal.width</th>\n","      <th>petal.length</th>\n","      <th>petal.width</th>\n","      <th>variety</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.1</td>\n","      <td>3.5</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.9</td>\n","      <td>3.0</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.7</td>\n","      <td>3.2</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.6</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.0</td>\n","      <td>3.6</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   sepal.length  sepal.width  petal.length  petal.width  variety\n","0           5.1          3.5           1.4          0.2        0\n","1           4.9          3.0           1.4          0.2        0\n","2           4.7          3.2           1.3          0.2        0\n","3           4.6          3.1           1.5          0.2        0\n","4           5.0          3.6           1.4          0.2        0"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"eGEWO_9Yx-Ym","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622994678897,"user_tz":240,"elapsed":33,"user":{"displayName":"vedant dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKleU9y9wWyYjI0z0kjFpSMh-CBCSZOHmSja1_Pw=s64","userId":"04728257226452809178"}},"outputId":"64124458-b2a7-462d-c6a4-96d1aaab1ebd"},"source":["iris_df['variety'].value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2    50\n","1    50\n","0    50\n","Name: variety, dtype: int64"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"25gsnahH_J76","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1622994680383,"user_tz":240,"elapsed":193,"user":{"displayName":"vedant dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKleU9y9wWyYjI0z0kjFpSMh-CBCSZOHmSja1_Pw=s64","userId":"04728257226452809178"}},"outputId":"0153bce8-d370-407b-9421-61e6d05c599d"},"source":["print(iris_df.shape)\n","iris_df.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(150, 5)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sepal.length</th>\n","      <th>sepal.width</th>\n","      <th>petal.length</th>\n","      <th>petal.width</th>\n","      <th>variety</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.1</td>\n","      <td>3.5</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.9</td>\n","      <td>3.0</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.7</td>\n","      <td>3.2</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.6</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.0</td>\n","      <td>3.6</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   sepal.length  sepal.width  petal.length  petal.width  variety\n","0           5.1          3.5           1.4          0.2        0\n","1           4.9          3.0           1.4          0.2        0\n","2           4.7          3.2           1.3          0.2        0\n","3           4.6          3.1           1.5          0.2        0\n","4           5.0          3.6           1.4          0.2        0"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"SiKnDNgKDT5d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622995207616,"user_tz":240,"elapsed":252,"user":{"displayName":"vedant dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKleU9y9wWyYjI0z0kjFpSMh-CBCSZOHmSja1_Pw=s64","userId":"04728257226452809178"}},"outputId":"2512d4ca-8f84-448b-be7a-eb97f871d267"},"source":["iris_df.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(150, 5)"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"rMJHpdyl_mZq"},"source":["# Create features / labels and train / test splits\n","iris_x = iris_df.drop('variety', axis = 1)                                      # create training dataset (inputs for model)\n","iris_y = iris_df[['variety']]                                                   # create testing dataset (output column)\n","\n","X_train, x_test, Y_train, y_test = train_test_split(iris_x,\n","                                                    iris_y,\n","                                                    test_size=0.3,\n","                                                    random_state=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l4s-pZfR_-CD"},"source":["# Convert data from numpy format to pytorch tensor\n","X_train = torch.from_numpy(X_train.values).float()\n","X_test = torch.from_numpy(x_test.values).float()\n","y_train = torch.from_numpy(Y_train.values).view(1,-1)[0]\n","y_test = torch.from_numpy(y_test.values).view(1,-1)[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IQD1elZA_r8x"},"source":["# Model Development\n","\n","Here, we will use the simple Multi layer Perceptron model with three layers."]},{"cell_type":"code","metadata":{"id":"iNHE-rlk9Zpo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622995603372,"user_tz":240,"elapsed":168,"user":{"displayName":"vedant dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKleU9y9wWyYjI0z0kjFpSMh-CBCSZOHmSja1_Pw=s64","userId":"04728257226452809178"}},"outputId":"844727e8-d80f-4556-ef29-9477bb405888"},"source":["# Simple MLP for demonstration serialization\n","\n","input_size = 4\n","output_size = 3\n","hidden_size = 30\n","\n","class IrisNet(nn.Module):\n","    def __init__(self):\n","        super(IrisNet, self).__init__()\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.fc2 = nn.Linear(hidden_size, hidden_size)\n","        self.fc3 = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, X):\n","        X = torch.sigmoid((self.fc1(X)))\n","        X = torch.sigmoid(self.fc2(X))\n","        X = self.fc3(X)\n","\n","        return F.log_softmax(X, dim=-1)\n","\n","\n","# Let's visualize the model.\n","model = IrisNet()\n","print(model)\n","summary(IrisNet(), (4,))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["IrisNet(\n","  (fc1): Linear(in_features=4, out_features=30, bias=True)\n","  (fc2): Linear(in_features=30, out_features=30, bias=True)\n","  (fc3): Linear(in_features=30, out_features=3, bias=True)\n",")\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1                   [-1, 30]             150\n","            Linear-2                   [-1, 30]             930\n","            Linear-3                    [-1, 3]              93\n","================================================================\n","Total params: 1,173\n","Trainable params: 1,173\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.00\n","Params size (MB): 0.00\n","Estimated Total Size (MB): 0.00\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TITSQdwc9fNQ"},"source":["# initialize the network and define the optimizer and loss function\n","model = IrisNet()\n","optimizer = optim.Adam(model.parameters(), lr = 0.03)\n","loss_fn = nn.NLLLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lxaZAGlTBgpk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622995699187,"user_tz":240,"elapsed":507,"user":{"displayName":"vedant dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKleU9y9wWyYjI0z0kjFpSMh-CBCSZOHmSja1_Pw=s64","userId":"04728257226452809178"}},"outputId":"271f4f60-f1ad-4535-e1b2-57820d7190e4"},"source":["# Train the model\n","\n","epochs = 500\n","\n","for epoch in range(epochs):\n","    optimizer.zero_grad()\n","    y_pred = model(X_train)\n","    loss = loss_fn(y_pred , y_train)\n","    loss.backward()\n","    optimizer.step()\n","\n","    if epoch % 100 == 0:\n","        print(f'Epoch: {epoch} loss: {loss.item()}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch: 0 loss: 1.1344870328903198\n","Epoch: 100 loss: 0.022997340187430382\n","Epoch: 200 loss: 0.021345626562833786\n","Epoch: 300 loss: 0.020002977922558784\n","Epoch: 400 loss: 0.01113436371088028\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cp6gJ3G4C3Ud"},"source":["def inference(model, input):\n","  \"\"\"Conduct inference for a model\"\"\"\n","\n","  return torch.argmax(model(input))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s3vzh38jLWn4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622995721243,"user_tz":240,"elapsed":177,"user":{"displayName":"vedant dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKleU9y9wWyYjI0z0kjFpSMh-CBCSZOHmSja1_Pw=s64","userId":"04728257226452809178"}},"outputId":"7faa2e96-d9b7-40cb-c4b1-98a65f3afe3b"},"source":["example = torch.tensor([5.1, 3.5, 1.4, 0.2])\n","\n","pred = inference(model, example)\n","print(pred)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor(0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ie4aquJeD3qC"},"source":["# Serialize the model\n","\n","### Why Serialization in Machine Learning:\n","\n","The serialization is practice to convert data in serialize format. In machine learning whenever you train the model it takes time and computation power as well. Some model are too complex that takes hours of time for train themselves. In case, if we require to use model in later period of time, then best to save the trained model and reuse whenever requried. The advangate of serialization is that **the Serialize format are much faster to load with compariosn to json or SQL foramt file.**\n","\n","Practically, the trained model are considered as python object. In serialization we just convert that python object to serialize format which consist the specific dataformat for serializing perfectly."]},{"cell_type":"code","metadata":{"id":"MR9G7nzSF3AN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622995920499,"user_tz":240,"elapsed":56475,"user":{"displayName":"vedant dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKleU9y9wWyYjI0z0kjFpSMh-CBCSZOHmSja1_Pw=s64","userId":"04728257226452809178"}},"outputId":"f0481305-9163-488a-8bcb-c7572a58f9b3"},"source":["# Mount to google drive in order to save there\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PTWNNyvXJawC"},"source":["model_name = 'iris_model.pt'\n","model_path = f\"/content/drive/MyDrive/OpenSource/trained_models/{model_name}\" "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kxd7RHgzKnMa"},"source":["# Method1: Save the model using inbuild pycharm library\n","torch.save(model, model_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rismSe1sKO14","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622996043625,"user_tz":240,"elapsed":212,"user":{"displayName":"vedant dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKleU9y9wWyYjI0z0kjFpSMh-CBCSZOHmSja1_Pw=s64","userId":"04728257226452809178"}},"outputId":"bfbf2edf-4771-4b7e-fc1b-67b6cd89df2a"},"source":["# Ensure the model was saved\n","! ls /content/drive/MyDrive/OpenSource/trained_models/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["iris_model.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QQw-tCz5FNyX"},"source":["# Load the same model\n","new_model = torch.load(model_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W8V75WFMCsiE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622996061280,"user_tz":240,"elapsed":222,"user":{"displayName":"vedant dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKleU9y9wWyYjI0z0kjFpSMh-CBCSZOHmSja1_Pw=s64","userId":"04728257226452809178"}},"outputId":"dffdbddf-96b9-4b70-940b-42ce8c14c947"},"source":["new_model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["IrisNet(\n","  (fc1): Linear(in_features=4, out_features=30, bias=True)\n","  (fc2): Linear(in_features=30, out_features=30, bias=True)\n","  (fc3): Linear(in_features=30, out_features=3, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"code","metadata":{"id":"wD1drMwaK7bf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622996065344,"user_tz":240,"elapsed":113,"user":{"displayName":"vedant dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKleU9y9wWyYjI0z0kjFpSMh-CBCSZOHmSja1_Pw=s64","userId":"04728257226452809178"}},"outputId":"55b97c97-07ea-4fc8-e658-cccdc7c405dd"},"source":["example = torch.tensor([5.1, 3.5, 1.4, 0.2])\n","pred = inference(new_model, example)\n","print(pred)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor(0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Xn3wsI1sGrjR"},"source":["#### here, we get the same model as before."]},{"cell_type":"markdown","metadata":{"id":"-n8fnv3KLkel"},"source":["# state_dictionary\n","\n","This dictionary consist all the trained parameter of model. It's easy to observe that the wight nd biases are saved seperately in serialize format."]},{"cell_type":"code","metadata":{"id":"kCv8WY3yJVyx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622996093466,"user_tz":240,"elapsed":191,"user":{"displayName":"vedant dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKleU9y9wWyYjI0z0kjFpSMh-CBCSZOHmSja1_Pw=s64","userId":"04728257226452809178"}},"outputId":"64945ead-cefc-4c16-cd95-e2213b024141"},"source":["model.state_dict()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('fc1.weight', tensor([[-0.7039, -0.7232,  1.2626,  0.9212],\n","                      [-0.8046,  0.2032,  0.9405,  1.1627],\n","                      [ 0.0496, -1.0466,  1.4352,  1.2532],\n","                      [ 0.0384,  0.7688, -0.6563, -0.9698],\n","                      [ 0.4449,  0.5505, -1.1367, -0.3181],\n","                      [ 0.2441,  0.3431, -0.6200, -1.0291],\n","                      [ 0.4258,  0.1790, -0.5916, -1.4542],\n","                      [ 0.3147,  0.7842, -1.0299, -0.7441],\n","                      [-0.6479, -0.2598,  0.9885,  0.8326],\n","                      [ 0.2466,  0.5842, -0.9097, -0.2893],\n","                      [-0.5972, -0.4321,  1.0531,  1.1189],\n","                      [ 0.5840, -0.0381, -0.8366, -0.9032],\n","                      [-0.3388, -0.6425,  0.9253,  0.6968],\n","                      [ 0.7705,  0.8602,  0.9352,  0.4550],\n","                      [-0.5446, -0.3042,  1.1199,  0.5714],\n","                      [ 0.6133,  0.3940, -1.0259, -0.8739],\n","                      [-0.0204, -1.1009,  0.9160,  0.6524],\n","                      [ 0.5666,  0.1703, -0.9832, -0.8417],\n","                      [ 0.1220, -0.4086, -0.3023, -0.2322],\n","                      [-0.1777,  0.1677, -0.3462, -0.4671],\n","                      [ 0.3341,  0.4946, -0.9038, -0.8199],\n","                      [ 0.7574,  0.2752, -1.3193, -0.4818],\n","                      [ 0.1271, -1.5579,  1.4022,  1.5970],\n","                      [ 0.4578,  0.6451, -0.9966, -0.9249],\n","                      [ 0.6031,  0.3873, -1.2152, -0.4603],\n","                      [ 0.3584,  0.2646, -0.6906, -1.1536],\n","                      [-0.5024, -0.3223,  1.0181,  0.5895],\n","                      [-0.4805, -0.8211,  1.1535,  0.7453],\n","                      [ 0.2349, -1.5575,  0.9607,  0.3864],\n","                      [-0.0456,  0.4527, -0.5178, -0.3981]])),\n","             ('fc1.bias',\n","              tensor([-0.6654, -1.0474, -0.7044,  0.8807,  0.9664,  0.7296,  0.6348,  1.1243,\n","                      -0.5532,  0.5834, -1.4401,  0.9559, -0.7292,  0.4016, -1.6427,  0.6430,\n","                      -1.0690,  1.3842,  0.2923,  0.1764,  1.4428,  1.2030, -0.2763,  0.7974,\n","                       1.2675,  1.1390, -1.2594, -0.7441, -0.9635, -0.1226])),\n","             ('fc2.weight',\n","              tensor([[-1.1058e+00, -9.2373e-01, -1.1477e-02,  8.8964e-01,  9.0010e-01,\n","                        9.6021e-01,  1.5926e+00,  1.4283e+00, -5.9302e-01,  1.8812e+00,\n","                       -1.1055e+00,  8.5984e-01, -6.0271e-01,  2.6577e-01, -9.8518e-01,\n","                        1.4622e+00, -7.3898e-01,  1.9334e+00,  6.1943e-01,  5.9666e-02,\n","                        1.6507e+00,  1.3403e+00, -3.7103e-02,  1.3164e+00,  1.6188e+00,\n","                        7.4372e-01, -5.5621e-01, -8.6197e-01, -6.1545e-01, -2.1012e-02],\n","                      [ 1.1248e+00,  1.0282e+00,  7.2755e-01, -3.4236e-01, -5.6941e-01,\n","                       -4.0086e-01, -3.3578e-01, -7.5085e-01,  9.2201e-01, -6.4616e-01,\n","                        1.1630e+00, -2.3880e-01,  1.3851e+00,  6.4315e-01,  7.6801e-01,\n","                       -5.1695e-01,  9.8196e-01, -3.8876e-01,  1.1906e-01,  8.5816e-02,\n","                       -4.5353e-01, -6.4404e-01,  1.0215e+00, -4.3090e-01, -4.0750e-01,\n","                       -4.0896e-01,  8.1781e-01,  9.3791e-01,  1.0524e+00, -1.2982e-01],\n","                      [-2.4272e-01, -7.6987e-01, -4.6196e-02,  2.9771e-01,  8.6893e-02,\n","                        2.8710e-01,  8.2662e-01,  5.3722e-01, -9.6101e-02, -4.1264e-02,\n","                       -5.2222e-01,  2.3413e-01, -3.6919e-01, -1.0744e-01, -5.9639e-01,\n","                        3.2652e-01, -3.3844e-01,  1.0908e+00,  4.7220e-01, -1.5935e-01,\n","                        5.3808e-01,  5.9962e-01,  5.6042e-02,  4.6761e-01,  7.9373e-01,\n","                        5.4027e-01, -1.9257e-01, -2.4871e-01,  4.0706e-02, -1.5939e-01],\n","                      [ 1.1437e+00,  1.2384e+00, -5.7581e-02, -1.3199e+00, -1.3906e+00,\n","                       -1.4361e+00, -1.5346e+00, -1.4688e+00,  6.6554e-01, -1.9951e+00,\n","                        1.1832e+00, -1.6611e+00,  1.1098e+00, -1.5686e-01,  1.0326e+00,\n","                       -1.5117e+00,  5.1534e-01, -1.8763e+00, -1.2426e+00, -2.7250e-01,\n","                       -1.6647e+00, -1.9573e+00,  1.3166e-01, -1.3339e+00, -1.6598e+00,\n","                       -1.2056e+00,  7.0216e-01,  1.0310e+00,  8.6139e-01, -5.4662e-01],\n","                      [ 1.0110e+00,  8.4707e-01,  7.8445e-01, -4.9516e-01, -3.7270e-01,\n","                       -3.3214e-01, -1.2049e-01, -6.4879e-01,  8.5707e-01, -8.3332e-01,\n","                        9.5061e-01, -1.8535e-01,  1.1570e+00,  3.4841e-01,  6.3594e-01,\n","                       -3.7538e-01,  7.9790e-01, -3.0195e-01,  3.7705e-01,  1.4025e-01,\n","                       -4.8443e-01, -3.3936e-01,  7.5618e-01, -6.2107e-01, -3.4807e-01,\n","                        3.8144e-02,  8.1858e-01,  7.8706e-01,  9.4741e-01, -1.1078e-01],\n","                      [ 9.9624e-01,  1.1220e+00,  7.0665e-01, -2.7695e-01, -3.6473e-01,\n","                       -2.1098e-01, -3.2582e-01, -5.9019e-01,  6.5151e-01, -5.7269e-01,\n","                        1.0901e+00,  1.6183e-02,  9.1215e-01,  4.1129e-01,  8.9893e-01,\n","                       -5.2897e-01,  6.6423e-01, -3.3136e-01,  7.9846e-02, -1.1340e-01,\n","                       -4.6559e-01, -3.9048e-01,  8.1189e-01, -6.5701e-01, -6.3719e-01,\n","                       -1.7952e-01,  6.9413e-01,  8.6360e-01,  1.1496e+00,  4.5818e-02],\n","                      [-8.9005e-01, -8.9833e-01, -1.3388e-01,  1.0090e+00,  1.0859e+00,\n","                        8.5872e-01,  1.3006e+00,  1.6768e+00, -5.7582e-01,  1.9597e+00,\n","                       -9.1382e-01,  6.8704e-01, -6.6326e-01, -1.4048e-01, -7.9680e-01,\n","                        1.6459e+00, -6.7098e-01,  1.9839e+00,  3.4774e-01,  4.3868e-02,\n","                        1.8258e+00,  1.7512e+00, -2.8283e-01,  1.5408e+00,  2.1993e+00,\n","                        1.0033e+00, -6.7697e-01, -9.4608e-01, -7.4124e-01,  8.5813e-02],\n","                      [ 8.8692e-01,  9.3794e-01,  6.7753e-01, -4.4037e-01, -4.0356e-01,\n","                       -1.6729e-01, -2.4660e-01, -4.1252e-01,  7.4509e-01, -6.9606e-01,\n","                        9.8070e-01, -8.0782e-02,  1.2673e+00,  5.1666e-01,  8.3740e-01,\n","                       -7.8840e-01,  1.0395e+00, -3.6589e-01,  1.3749e-01, -1.5647e-01,\n","                       -3.8876e-01, -6.6402e-01,  9.3555e-01, -4.0357e-01, -3.6184e-01,\n","                       -4.0697e-01,  7.9415e-01,  1.1101e+00,  9.0219e-01, -1.6958e-01],\n","                      [-8.0726e-01, -5.7074e-01, -5.3419e-01,  1.2320e-01,  1.3434e-01,\n","                        2.9742e-01,  6.5716e-01,  6.1818e-01, -6.6325e-01,  9.5574e-01,\n","                       -6.9318e-01, -1.4920e-01, -8.5744e-01, -4.4122e-01, -5.4104e-01,\n","                        5.4562e-01, -7.9290e-01,  5.0574e-01, -5.8080e-01, -1.0593e-01,\n","                        6.5794e-01,  1.7967e-01, -5.8676e-01,  1.4248e-01,  6.2755e-01,\n","                       -1.8358e-02, -4.0452e-01, -6.3563e-01, -6.1577e-01,  4.9416e-02],\n","                      [-1.0649e+00, -9.9295e-01,  2.0155e-01,  9.8798e-01,  1.1255e+00,\n","                        1.1128e+00,  1.4506e+00,  1.3345e+00, -5.7311e-01,  1.6717e+00,\n","                       -1.1836e+00,  1.1576e+00, -9.0868e-01,  2.7927e-01, -1.0874e+00,\n","                        1.3461e+00, -7.0807e-01,  1.5732e+00,  8.8901e-01,  4.1307e-01,\n","                        1.5015e+00,  1.3944e+00,  7.3796e-02,  1.1239e+00,  1.3701e+00,\n","                        8.8271e-01, -4.9017e-01, -1.1236e+00, -7.8269e-01,  5.4503e-01],\n","                      [-7.6533e-01, -1.1624e+00,  2.8042e-01,  7.6159e-01,  9.0476e-01,\n","                        9.2571e-01,  1.3783e+00,  1.4043e+00, -5.5874e-01,  1.1943e+00,\n","                       -1.0004e+00,  8.2754e-01, -5.2784e-01, -8.1305e-02, -9.4270e-01,\n","                        1.5262e+00, -6.4984e-01,  1.7415e+00,  7.8651e-01, -4.3702e-02,\n","                        1.4956e+00,  1.5846e+00, -8.0436e-02,  1.1483e+00,  1.6884e+00,\n","                        9.5515e-01, -7.3755e-01, -7.5781e-01, -4.5634e-01,  4.9460e-02],\n","                      [-1.0604e+00, -1.1551e+00, -2.8609e-03,  9.8706e-01,  1.0521e+00,\n","                        1.2017e+00,  1.4668e+00,  1.3766e+00, -5.9011e-01,  1.4608e+00,\n","                       -9.3298e-01,  1.1015e+00, -4.5906e-01,  1.0557e-01, -8.7368e-01,\n","                        1.3345e+00, -6.4499e-01,  1.5447e+00,  1.0062e+00,  1.5549e-01,\n","                        1.4164e+00,  1.4184e+00,  5.7108e-02,  1.2225e+00,  1.4721e+00,\n","                        9.4723e-01, -6.4368e-01, -8.9265e-01, -5.2690e-01,  3.7375e-01],\n","                      [-1.3750e+00, -1.2500e+00,  2.8280e-01,  9.6817e-01,  1.3455e+00,\n","                        1.2732e+00,  1.4947e+00,  1.3633e+00, -5.2339e-01,  1.5480e+00,\n","                       -1.1054e+00,  1.3684e+00, -1.0277e+00,  4.6672e-01, -1.1678e+00,\n","                        1.2287e+00, -8.3226e-01,  1.6989e+00,  1.2924e+00,  3.5964e-01,\n","                        1.4703e+00,  1.4620e+00,  2.0079e-01,  1.2215e+00,  1.3808e+00,\n","                        1.2948e+00, -7.4276e-01, -9.9987e-01, -6.5039e-01,  5.1734e-01],\n","                      [-1.0294e+00, -1.1036e+00,  3.2329e-02,  7.7925e-01,  1.0100e+00,\n","                        9.9276e-01,  1.2692e+00,  1.2100e+00, -5.2298e-01,  1.4644e+00,\n","                       -1.2503e+00,  8.4382e-01, -3.0162e-01,  3.2131e-01, -1.0596e+00,\n","                        1.4802e+00, -4.7330e-01,  1.5479e+00,  8.5630e-01,  2.8118e-01,\n","                        1.5629e+00,  1.5609e+00, -6.4361e-02,  1.2203e+00,  1.5163e+00,\n","                        1.1037e+00, -8.2772e-01, -1.0009e+00, -4.8341e-01,  2.3751e-01],\n","                      [-1.2877e+00, -1.0276e+00,  7.2921e-02,  1.0436e+00,  1.0875e+00,\n","                        9.8863e-01,  1.3734e+00,  1.1689e+00, -5.3544e-01,  1.8055e+00,\n","                       -1.3069e+00,  1.1398e+00, -6.9071e-01,  3.3804e-01, -9.6901e-01,\n","                        1.3860e+00, -5.4396e-01,  1.7684e+00,  9.7027e-01,  3.6976e-01,\n","                        1.6728e+00,  1.5082e+00,  1.2461e-01,  1.1633e+00,  1.4524e+00,\n","                        1.0995e+00, -7.6986e-01, -1.2600e+00, -6.5337e-01,  5.4592e-01],\n","                      [ 1.1257e+00,  6.6654e-01,  6.0137e-01, -3.1885e-01, -3.5586e-01,\n","                       -4.8054e-01, -2.1982e-01, -6.3316e-01,  6.5978e-01, -7.0329e-01,\n","                        6.9799e-01, -2.8418e-01,  1.0230e+00,  3.3452e-01,  7.0957e-01,\n","                       -5.1130e-01,  7.7855e-01, -1.4849e-01,  4.3819e-01, -2.2125e-01,\n","                       -3.8200e-01, -5.7142e-02,  5.6013e-01, -5.0198e-01, -5.6853e-01,\n","                       -7.6815e-02,  7.4719e-01,  1.1310e+00,  8.9113e-01, -1.3723e-01],\n","                      [-8.9966e-01, -1.1808e+00, -6.6843e-01,  6.4522e-01,  1.1563e-01,\n","                        5.2666e-01,  7.1785e-01,  5.3204e-01, -1.2041e+00,  9.2119e-01,\n","                       -1.4301e+00, -5.1532e-02, -8.9466e-01, -4.1325e-01, -1.0323e+00,\n","                        7.9708e-01, -1.4123e+00,  4.4107e-01, -6.1911e-01, -1.5954e-01,\n","                        8.7536e-01,  3.7497e-01, -1.3760e+00,  2.7562e-01,  3.7271e-01,\n","                        6.2464e-02, -9.4132e-01, -1.4036e+00, -1.2181e+00,  1.0580e-01],\n","                      [-9.2499e-01, -8.3267e-01, -1.8400e-01,  9.9570e-01,  8.3121e-01,\n","                        1.1237e+00,  1.4271e+00,  1.4590e+00, -5.1143e-01,  1.8173e+00,\n","                       -1.1223e+00,  6.4677e-01, -5.8042e-01,  1.5451e-02, -6.4408e-01,\n","                        1.4555e+00, -5.1632e-01,  1.8475e+00,  5.5595e-01,  1.6971e-01,\n","                        1.5571e+00,  1.5690e+00,  5.0783e-02,  1.2514e+00,  1.6310e+00,\n","                        7.8192e-01, -5.7132e-01, -8.9801e-01, -8.1587e-01,  3.1105e-01],\n","                      [-1.3165e+00, -1.3083e+00,  2.0265e-01,  1.1459e+00,  1.2484e+00,\n","                        1.0920e+00,  1.5581e+00,  1.4139e+00, -4.9514e-01,  1.9017e+00,\n","                       -1.4612e+00,  1.0972e+00, -8.7623e-01,  2.1439e-01, -9.3431e-01,\n","                        1.3530e+00, -7.4200e-01,  1.7112e+00,  1.2690e+00,  6.0405e-01,\n","                        1.5734e+00,  1.5457e+00,  2.0890e-01,  1.3438e+00,  1.6459e+00,\n","                        1.1882e+00, -7.7049e-01, -1.2910e+00, -7.8867e-01,  4.2483e-01],\n","                      [ 1.1171e+00,  1.1548e+00,  7.5810e-01, -5.2500e-01, -2.0146e-01,\n","                       -4.9111e-01, -3.9707e-01, -5.3011e-01,  9.0488e-01, -8.4185e-01,\n","                        8.6464e-01, -6.4884e-02,  1.1370e+00,  4.2157e-01,  9.4142e-01,\n","                       -5.8601e-01,  7.7366e-01, -3.4532e-01,  1.0255e-01,  2.3736e-01,\n","                       -3.9739e-01, -4.1400e-01,  7.4578e-01, -5.1668e-01, -6.2400e-01,\n","                       -1.8113e-01,  7.6878e-01,  1.1499e+00,  1.2390e+00,  1.1414e-02],\n","                      [-9.7372e-01, -8.8841e-01,  8.3929e-02,  1.0009e+00,  8.8772e-01,\n","                        9.8525e-01,  1.4418e+00,  1.4378e+00, -6.0016e-01,  1.7150e+00,\n","                       -1.2703e+00,  7.7510e-01, -6.8533e-01,  2.7315e-01, -9.9285e-01,\n","                        1.4286e+00, -6.1905e-01,  1.8889e+00,  9.0625e-01,  1.3496e-01,\n","                        1.4395e+00,  1.3838e+00, -1.0786e-01,  1.0347e+00,  1.5815e+00,\n","                        7.3158e-01, -7.3326e-01, -8.3533e-01, -6.7510e-01,  4.7590e-01],\n","                      [ 7.4055e-01,  8.7524e-01,  9.3050e-03, -7.8644e-01, -7.6726e-01,\n","                       -8.0397e-01, -1.0182e+00, -1.4001e+00,  2.8538e-01, -8.7480e-01,\n","                        8.3618e-01, -6.6785e-01,  4.8863e-01,  1.6204e-02,  8.4081e-01,\n","                       -1.1487e+00,  5.2012e-01, -1.5898e+00, -1.0097e+00, -3.3405e-01,\n","                       -1.2617e+00, -1.6982e+00,  1.6929e-01, -1.3863e+00, -1.8316e+00,\n","                       -9.4616e-01,  7.3224e-01,  7.7041e-01,  4.5616e-01, -1.8154e-01],\n","                      [ 9.7416e-01,  1.2929e+00,  9.3225e-01, -3.7128e-01, -5.9149e-01,\n","                       -4.7059e-01, -4.1715e-01, -4.6155e-01,  1.0956e+00, -6.0518e-01,\n","                        1.1134e+00, -2.1237e-01,  1.0976e+00,  4.8793e-01,  7.8028e-01,\n","                       -5.6191e-01,  7.8887e-01, -3.6430e-01,  7.4813e-02,  4.8522e-02,\n","                       -3.1229e-01, -4.9735e-01,  1.1154e+00, -6.6780e-01, -5.7717e-01,\n","                       -2.5283e-01,  8.9747e-01,  9.1689e-01,  1.2130e+00, -9.2244e-02],\n","                      [-7.1600e-01, -1.2209e+00, -8.8311e-01,  3.0959e-01, -2.5901e-02,\n","                        6.4315e-01,  1.6557e+00,  3.0702e-01, -8.0517e-01,  1.8488e+00,\n","                       -1.5077e+00,  1.3235e-03, -9.5121e-01, -7.6234e-01, -6.1814e-01,\n","                        4.9326e-01, -1.1431e+00,  7.2909e-01, -3.1356e-01, -2.8328e-01,\n","                        8.9750e-01, -2.2036e-01, -1.1183e+00,  4.4071e-02,  3.9129e-01,\n","                        1.4394e-01, -9.2713e-01, -1.0826e+00, -1.2247e+00, -1.1891e-01],\n","                      [-9.8389e-01, -6.4386e-01, -8.4477e-01,  4.5085e-01,  2.4604e-01,\n","                        7.4827e-02,  4.1945e-01,  5.1668e-01, -6.3794e-01,  1.1515e+00,\n","                       -8.3345e-01,  3.9238e-02, -1.0392e+00, -4.6633e-01, -7.2765e-01,\n","                        6.0440e-01, -9.8241e-01,  1.8330e-01, -4.6080e-01,  1.7468e-02,\n","                        7.5960e-01,  4.7882e-01, -7.8439e-01,  5.2367e-01,  4.2625e-01,\n","                       -9.4758e-02, -7.0970e-01, -8.4441e-01, -9.1218e-01,  3.7026e-02],\n","                      [ 9.0001e-01,  1.1790e+00,  7.8298e-01, -5.1481e-01, -2.4649e-01,\n","                       -3.1112e-01, -4.0629e-01, -6.8043e-01,  9.5463e-01, -1.7867e-01,\n","                        8.3727e-01, -2.0564e-02,  1.0527e+00,  5.1302e-01,  8.4206e-01,\n","                       -6.9192e-01,  7.5896e-01, -5.2735e-01,  7.6105e-02, -1.2611e-01,\n","                       -4.2563e-01, -5.8544e-01,  1.0850e+00, -4.0328e-01, -6.1024e-01,\n","                       -4.1162e-01,  7.4996e-01,  1.1008e+00,  9.3850e-01, -8.2734e-02],\n","                      [ 1.0087e+00,  8.9690e-01,  6.2937e-01, -3.7397e-01, -3.3955e-01,\n","                       -2.1548e-01, -3.0851e-01, -6.7583e-01,  8.3644e-01, -5.2786e-01,\n","                        1.0011e+00, -7.5867e-02,  8.4962e-01,  4.7152e-01,  8.5739e-01,\n","                       -6.7879e-01,  9.4735e-01, -1.0230e-01,  2.1079e-02,  2.5392e-01,\n","                       -5.5373e-01, -4.8514e-01,  7.2300e-01, -4.4456e-01, -5.1466e-01,\n","                       -2.3785e-01,  6.4511e-01,  9.7329e-01,  8.8806e-01,  1.1553e-01],\n","                      [ 1.0379e+00,  8.0733e-01,  4.1838e-01, -1.2735e-01, -8.8935e-02,\n","                       -2.5769e-01, -2.6385e-01, -5.7537e-01,  4.0719e-01,  1.2149e-01,\n","                        8.0293e-01, -1.5391e-02,  8.3636e-01,  3.6355e-01,  5.5672e-01,\n","                       -5.3132e-01,  7.2075e-01, -3.0356e-01,  1.5352e-01, -1.7075e-01,\n","                       -5.0984e-01, -5.2781e-01,  7.0880e-01, -5.0620e-01, -5.6349e-01,\n","                       -3.7049e-01,  6.8141e-01,  9.3663e-01,  8.9352e-01, -1.2950e-01],\n","                      [ 1.0499e+00,  1.3544e+00, -1.4967e-03, -1.2877e+00, -1.1178e+00,\n","                       -1.4747e+00, -1.5302e+00, -1.4398e+00,  6.2969e-01, -1.8552e+00,\n","                        1.3784e+00, -1.1527e+00,  7.5564e-01, -4.6810e-01,  1.2195e+00,\n","                       -1.3368e+00,  7.9461e-01, -1.9024e+00, -9.5111e-01, -5.5310e-01,\n","                       -1.7324e+00, -1.6875e+00, -4.0620e-02, -1.4772e+00, -1.7103e+00,\n","                       -1.3807e+00,  8.7766e-01,  1.1030e+00,  7.6543e-01, -4.7404e-01],\n","                      [ 1.2130e+00,  1.2052e+00,  2.0097e-01, -1.4779e+00, -1.8108e+00,\n","                       -1.2261e+00, -1.5198e+00, -1.7122e+00,  6.8937e-01, -1.5822e+00,\n","                        1.3276e+00, -1.3783e+00,  1.0375e+00, -1.1960e-01,  8.5508e-01,\n","                       -1.7085e+00,  5.7263e-01, -1.8982e+00, -7.7756e-01, -3.0460e-01,\n","                       -1.7987e+00, -2.0828e+00,  1.1453e-01, -1.8389e+00, -2.0153e+00,\n","                       -1.3764e+00,  7.1142e-01,  7.9129e-01,  7.4526e-01, -5.3248e-01]])),\n","             ('fc2.bias',\n","              tensor([ 0.0884,  0.7093, -0.2336, -0.2147,  0.3146,  0.4459,  0.0494,  0.5247,\n","                      -0.6232,  0.4303, -0.0093,  0.0296,  0.2409,  0.0961,  0.2934,  0.5211,\n","                      -0.4226, -0.0221,  0.5715,  0.5858,  0.3171,  0.1429,  0.5430, -0.5371,\n","                      -0.5556,  0.5644,  0.3775,  0.1243, -0.3760,  0.1597])),\n","             ('fc3.weight',\n","              tensor([[ 0.7464, -0.8887,  0.3030, -0.5741, -0.8966, -0.9120,  0.4303, -0.7802,\n","                        0.7414,  1.0049,  0.9923,  0.5695,  0.8760,  0.8120,  0.8011, -0.7356,\n","                        0.6583,  0.8738,  0.6562, -0.8503,  0.6862, -0.2376, -0.7661,  0.4948,\n","                        0.8382, -0.9352, -1.0288, -0.8129, -0.6435, -0.4503],\n","                      [ 0.5898,  0.4729, -0.0808, -0.9167,  0.5595,  0.3970,  0.3652,  0.3625,\n","                       -0.5524,  0.6860,  0.4426,  0.6092,  0.9954,  0.5269,  0.8230,  0.2589,\n","                       -1.0399,  0.4790,  0.7014,  0.3808,  0.6238, -0.7634,  0.3592, -0.9358,\n","                       -0.8929,  0.1414,  0.5081,  0.1894, -0.9054, -1.4677],\n","                      [-1.2966,  0.9355, -0.4090,  1.5335,  0.7713,  0.9079, -1.1249,  0.8969,\n","                       -0.4096, -1.4397, -1.7754, -1.7068, -1.8105, -1.7683, -1.4606,  0.7862,\n","                       -0.3703, -1.1225, -1.3865,  0.9022, -1.4306,  0.9852,  0.9617, -0.2475,\n","                       -0.5902,  0.8644,  1.0604,  1.0458,  1.6324,  1.6743]])),\n","             ('fc3.bias', tensor([ 0.1598, -0.2227,  0.1241]))])"]},"metadata":{"tags":[]},"execution_count":61}]},{"cell_type":"code","metadata":{"id":"RusVflSxJsu3"},"source":["model_name = 'iris_model_state_dict.pt'\n","model_path = f\"/content/drive/MyDrive/OpenSource/trained_models/{model_name}\" \n","\n","# Save the models state_dict\n","torch.save(model.state_dict(), model_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o9aWdGmsM754","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622996282046,"user_tz":240,"elapsed":183,"user":{"displayName":"vedant dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKleU9y9wWyYjI0z0kjFpSMh-CBCSZOHmSja1_Pw=s64","userId":"04728257226452809178"}},"outputId":"d776b735-141a-400f-d9fb-4f7476469ece"},"source":["! ls /content/drive/MyDrive/OpenSource/trained_models/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["iris_model.pt  iris_model_state_dict.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-Pr0QjV9M8vw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622996339223,"user_tz":240,"elapsed":135,"user":{"displayName":"vedant dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKleU9y9wWyYjI0z0kjFpSMh-CBCSZOHmSja1_Pw=s64","userId":"04728257226452809178"}},"outputId":"4dee67ab-3e8b-4d61-c4de-4fba4aaba80e"},"source":["model_name = 'iris_model_state_dict.pt'\n","model_path = f\"/content/drive/MyDrive/OpenSource/trained_models/{model_name}\" \n","\n","model.load_state_dict(torch.load(model_path))\n","print(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["IrisNet(\n","  (fc1): Linear(in_features=4, out_features=30, bias=True)\n","  (fc2): Linear(in_features=30, out_features=30, bias=True)\n","  (fc3): Linear(in_features=30, out_features=3, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VmxqQalnC0JL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622996342669,"user_tz":240,"elapsed":159,"user":{"displayName":"vedant dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKleU9y9wWyYjI0z0kjFpSMh-CBCSZOHmSja1_Pw=s64","userId":"04728257226452809178"}},"outputId":"80d38188-b65a-417d-bccc-508ffc5efd23"},"source":["example = torch.tensor([5.1, 3.5, 1.4, 0.2])\n","pred = inference(new_model, example)\n","print(pred)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor(0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IVHZcrNnHvsU"},"source":["###  We got the same result as before. The key difference between both we will explore in this (*link) notebook."]},{"cell_type":"code","metadata":{"id":"BnPoRxzyIDZP"},"source":["# prefinal [attempt 1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V_xDLK3gIK70"},"source":[""],"execution_count":null,"outputs":[]}]}