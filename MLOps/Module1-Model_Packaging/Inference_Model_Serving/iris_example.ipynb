{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "iris_example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JQKsH8DRm6H",
        "colab_type": "text"
      },
      "source": [
        "# Serving Models\n",
        "\n",
        "This notebook contains a PyTorch model trained on the Iris dataset.  We will be using this model throughout the remainder of the model serving material."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7my_vN8e9s7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install required python packages\n",
        "%%capture\n",
        "! pip install mlflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LsXt1MZV9QRx",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn\n",
        "import mlflow\n",
        "import mlflow.pyfunc\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmEsoeXsePBF",
        "colab_type": "code",
        "outputId": "782abe5e-1399-444a-91a2-b3d05a1498dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Mount our gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UfRBsUug-fpu",
        "outputId": "2d556351-fd5c-4ea0-e7ed-a064fa65a97b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# Download the csv to the content directory in colab\n",
        "# You can see the csv by opening the file explorer tab on the left of the screen\n",
        "# You may need to click the refresh button at the top of the file explorer window\n",
        "! wget https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-08 22:11:57--  https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3975 (3.9K) [text/plain]\n",
            "Saving to: ‘iris.csv’\n",
            "\n",
            "\riris.csv              0%[                    ]       0  --.-KB/s               \riris.csv            100%[===================>]   3.88K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-03-08 22:11:57 (111 MB/s) - ‘iris.csv’ saved [3975/3975]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rQ_prRPT_v2u"
      },
      "source": [
        "# Data Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oOLFYwNJjkDL",
        "outputId": "ff111f06-e135-4f26-9939-888f973955df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Load the csv into a pandas dataframe and inspect the data\n",
        "iris_df = pd.read_csv('/content/iris.csv')\n",
        "iris_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal.length</th>\n",
              "      <th>sepal.width</th>\n",
              "      <th>petal.length</th>\n",
              "      <th>petal.width</th>\n",
              "      <th>variety</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal.length  sepal.width  petal.length  petal.width variety\n",
              "0           5.1          3.5           1.4          0.2  Setosa\n",
              "1           4.9          3.0           1.4          0.2  Setosa\n",
              "2           4.7          3.2           1.3          0.2  Setosa\n",
              "3           4.6          3.1           1.5          0.2  Setosa\n",
              "4           5.0          3.6           1.4          0.2  Setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wbyEJLCGjLy7",
        "colab": {}
      },
      "source": [
        "# Initialize a label encoder for the class names\n",
        "# This is an example of a data artifact that will be required at inference time\n",
        "# Any data preprocessing artifacts should be packaged with the corresponding model\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "# Convert labels to ints\n",
        "iris_df['variety'] = label_encoder.fit_transform(iris_df['variety'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eGEWO_9Yx-Ym",
        "outputId": "5f2bc5e5-c885-4173-9da0-8df8d93d1a8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Label breakdown - we no longer have strings for class names\n",
        "iris_df['variety'].value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    50\n",
              "1    50\n",
              "0    50\n",
              "Name: variety, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "25gsnahH_J76",
        "outputId": "eca48baa-a73c-44bb-90a2-a99e822c0e1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# Inspect the data after label encoding\n",
        "print(iris_df.shape)\n",
        "iris_df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal.length</th>\n",
              "      <th>sepal.width</th>\n",
              "      <th>petal.length</th>\n",
              "      <th>petal.width</th>\n",
              "      <th>variety</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal.length  sepal.width  petal.length  petal.width  variety\n",
              "0           5.1          3.5           1.4          0.2        0\n",
              "1           4.9          3.0           1.4          0.2        0\n",
              "2           4.7          3.2           1.3          0.2        0\n",
              "3           4.6          3.1           1.5          0.2        0\n",
              "4           5.0          3.6           1.4          0.2        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rMJHpdyl_mZq",
        "colab": {}
      },
      "source": [
        "# Drop labels from out training features\n",
        "iris_x = iris_df.drop('variety', axis = 1)\n",
        "iris_y = iris_df[['variety']]\n",
        "\n",
        "# Generate train / test splits for training and evaluation\n",
        "X_train, x_test, Y_train, y_test = train_test_split(iris_x,\n",
        "                                                    iris_y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l4s-pZfR_-CD",
        "colab": {}
      },
      "source": [
        "# Convert to tensors\n",
        "X_train = torch.from_numpy(X_train.values).float()\n",
        "X_test = torch.from_numpy(x_test.values).float()\n",
        "y_train = torch.from_numpy(Y_train.values).view(1,-1)[0]\n",
        "y_test = torch.from_numpy(y_test.values).view(1,-1)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IQD1elZA_r8x"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxnqjdLVUnoS",
        "colab_type": "text"
      },
      "source": [
        "Models are typically created within a notebook but the model class should be separated out into its own Python file for packaging purposes.  Notebooks are great for experimenting with ideas but it can be a challenge to then take that code and structure it properly in a project format.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iNHE-rlk9Zpo",
        "colab": {}
      },
      "source": [
        "# PLEASE WATCH THE ACCOMPANYING VIDEO FOR THIS NOTEBOOK\n",
        "# NOTE: REMEBER IN THE VIDEO WE SEPERATED OUT OUR MODEL CLASS\n",
        "# INTO ITS OWN MODEL.PY FILE\n",
        "\n",
        "# We will eventually pull this model out into its own Python file for packaging\n",
        "\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# from torch.nn import functional as F\n",
        "\n",
        "# input_size = 4\n",
        "# output_size = 3\n",
        "# hidden_size = 30\n",
        "\n",
        "# class IrisNet(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(IrisNet, self).__init__()\n",
        "#         self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "#         self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "#         self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "#     def forward(self, X):\n",
        "#         X = torch.sigmoid((self.fc1(X)))\n",
        "#         X = torch.sigmoid(self.fc2(X))\n",
        "#         X = self.fc3(X)\n",
        "\n",
        "#         return F.log_softmax(X, dim=-1)\n",
        "\n",
        "\n",
        "# Since we move our model class to model.py\n",
        "# We can import it from the local file system\n",
        "# This files is included in the material\n",
        "from model import IrisNet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TITSQdwc9fNQ",
        "colab": {}
      },
      "source": [
        "# Initialize the network\n",
        "model = IrisNet()\n",
        "\n",
        "# Set the optamizer and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.03)\n",
        "loss_fn = nn.NLLLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lxaZAGlTBgpk",
        "outputId": "42e714c3-c816-42eb-fda3-5ec61bf9ba12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Train the model\n",
        "epochs = 500\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    y_pred = model(X_train)\n",
        "    loss = loss_fn(y_pred , y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch: {epoch} loss: {loss.item()}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 loss: 1.1216788291931152\n",
            "Epoch: 100 loss: 0.024891531094908714\n",
            "Epoch: 200 loss: 0.020291723310947418\n",
            "Epoch: 300 loss: 0.017456507310271263\n",
            "Epoch: 400 loss: 0.016022933647036552\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cp6gJ3G4C3Ud",
        "colab": {}
      },
      "source": [
        "def inference(model, user_input):\n",
        "    \"\"\"\n",
        "    Conduct inference for a model\n",
        "    Args:\n",
        "      model (torch): An instance of a torch model\n",
        "      user_input (tensor): User provided input strucutred as a tensor\n",
        "    Returns:\n",
        "      Predicted labels [(str)]\n",
        "    \"\"\"\n",
        "\n",
        "    # Get prediction\n",
        "    pred = torch.argmax(model(user_input), dim=1)\n",
        "\n",
        "    # Given the predicted integer, find the label from the label encoder\n",
        "    pred_labels = label_encoder.inverse_transform(pred)\n",
        "\n",
        "    return pred_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s3vzh38jLWn4",
        "outputId": "8de03479-2a6c-4ec7-a6b8-6d877edbf260",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Take a Setosa sample from X_test\n",
        "example = torch.tensor([[5.1, 3.5, 1.4, 0.2]])\n",
        "\n",
        "# Inference\n",
        "pred = inference(model, example)\n",
        "print(pred)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Setosa']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRcUdGHdWU80",
        "colab_type": "text"
      },
      "source": [
        "# Serializing data artifacts\n",
        "\n",
        "We will need to serialize a few data artifacts for this model:\n",
        "\n",
        "\n",
        "\n",
        "1.   Our PyTorch models state_dict\n",
        "2.   The label encoder used for transforming ints to their corresponding strings\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihClZRTaWy1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ClfBCHPdr4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Serialize the label encoder\n",
        "# This will be required at inference time\n",
        "le_path = '/content/label_encoder.pkl'\n",
        "with open(le_path, 'wb') as handle:\n",
        "    pickle.dump(label_encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycF5Gruodr4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Serialize the models state_dict\n",
        "state_dict_path = f'/content/state_dict.pt'\n",
        "torch.save(model.state_dict(), state_dict_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_kh1C3MXiI1",
        "colab_type": "code",
        "outputId": "4f8e34bf-54e2-44e4-920a-c580f20acc05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Inspect the data artifacts\n",
        "! ls /content"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive\t  label_encoder.pkl  __pycache__  state_dict.pt\n",
            "iris.csv  model.py\t     sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocxz89Z3RaVf",
        "colab_type": "text"
      },
      "source": [
        "# MLflow Packaging\n",
        "\n",
        "Now that we have everything serialized to disk it's time to package everything up together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn_DCm6Bdr4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here we will create an artifacts object\n",
        "# It will contain all of the data artifacts that we want to package with the model\n",
        "artifacts = {\n",
        "    \"state_dict\": state_dict_path,\n",
        "    \"label_encoder\": le_path\n",
        "}\n",
        "\n",
        "# This will serve as an MLflow wrapper for the model\n",
        "class ModelWrapper(mlflow.pyfunc.PythonModel):\n",
        "\n",
        "    # Load in the model and all required artifacts\n",
        "    # The context object is provided by the MLflow framework\n",
        "    # It will contain all of the artifacts specified above\n",
        "    def load_context(self, context):\n",
        "        import torch\n",
        "        import pickle\n",
        "        from model import IrisNet\n",
        "\n",
        "        # Initialize the model and load in the state dict\n",
        "        self.model = IrisNet()\n",
        "        self.model.load_state_dict(torch.load(context.artifacts[\"state_dict\"]))\n",
        "\n",
        "        # Load in and deserialize the label encoder object\n",
        "        with open(context.artifacts[\"label_encoder\"], 'rb') as handle:\n",
        "            self.label_encoder = pickle.load(handle)\n",
        "\n",
        "    # Create a predict function for our models\n",
        "    def predict(self, context, model_input):\n",
        "      \n",
        "        example = torch.tensor(model_input.values)\n",
        "        pred = torch.argmax(model(example.float()), dim=1)\n",
        "        pred_labels = self.label_encoder.inverse_transform(pred)\n",
        "        return pred_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mijZDTgcdzPE",
        "colab_type": "code",
        "outputId": "832f1409-acf3-414d-964d-55d6437babeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Inspect the default conda environment for MLflow\n",
        "mlflow.pyfunc.get_default_conda_env()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'channels': ['defaults'],\n",
              " 'dependencies': ['python=3.6.9', {'pip': ['mlflow', 'cloudpickle==1.2.2']}],\n",
              " 'name': 'mlflow-env'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRaLoPw1ayt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PLEASE NOTE: I HAVE CHANGED THE DICT STRUCTURE SLIGHTY FROM THE VIDEO\n",
        "\n",
        "# Let's create our own conda environment\n",
        "conda_env = {\n",
        "    'channels': ['defaults'],\n",
        "    'dependencies': [\n",
        "      f'python=3.6.9',\n",
        "      {\n",
        "          'pip':[\n",
        "            f'mlflow=={mlflow.__version__}',\n",
        "            f'torch=={torch.__version__}',\n",
        "            f'scikit-learn=={sklearn.__version__}',\n",
        "            'cloudpickle==1.2.2'\n",
        "          ]\n",
        "      }\n",
        "    ],\n",
        "    'name': 'mlflow-env'\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cok2toOTdr4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Location in our gdrive where we want the model to be saved\n",
        "mlflow_pyfunc_model_path = f\"/content/gdrive/My Drive/MLOPS/hands_on/models/iris_model\"\n",
        "\n",
        "# Package the model!\n",
        "mlflow.pyfunc.save_model(path=mlflow_pyfunc_model_path,\n",
        "                         python_model=ModelWrapper(),\n",
        "                         artifacts=artifacts,\n",
        "                         conda_env=conda_env,\n",
        "                         code_path=['/content/model.py', '/content/meta_data.txt'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyYwS-H-dr4y",
        "colab_type": "code",
        "outputId": "8c5dee71-0277-40b1-c983-307357b2add0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the model in `python_function` format\n",
        "loaded_model = mlflow.pyfunc.load_model(mlflow_pyfunc_model_path)\n",
        "\n",
        "# Evaluate the model\n",
        "test_predictions = loaded_model.predict(pd.DataFrame([[5.1, 3.5, 1.4, 0.2]]))\n",
        "print(test_predictions)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Setosa']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y52-SLpx-iv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}